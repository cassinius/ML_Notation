@book{Duda:2000:PatternRecognition,
   year = {2000},
   author = {Duda, Richard O. and Hart, Peter E. and Stork, David G.},
   title = {Pattern Classification. Second Edition},
   publisher = {Wiley},
   address = {New York et al.},
   pages = {654}
}


@article{Holzinger:2016:iML,
   year = {2016},
   author = {Holzinger, Andreas},
   title = {Interactive Machine Learning for Health Informatics: When do we need the human-in-the-loop?},
   journal = {Springer Brain Informatics (BRIN)},
   volume = {3},
   pages = {1-13},
   abstract = {Machine learning (ML) is the fastest growing field in computer science, and health informatics is amongst the greatest challenges. The goal of ML is to develop algorithms which can learn and improve over time and can be used for predictions. Most ML researchers concentrate on automatic Machine Learning (aML), where great advances have been made, for example, in speech recognition, recommender systems, or autonomous vehicles. Automatic approaches greatly benefit from big data with many training sets. However, in the health domain, sometimes we are confronted with a small number of data sets or rare events, where aML-approaches suffer of insufficient training samples. Here interactive Machine Learning (iML) may be of help, having its roots in Reinforcement Learning (RL), Preference Learning (PL) and Active Learning (AL). The term iML is not yet well used, so we define it as algorithms that can interact with agents and can optimize their learning behaviour through these interactions, where the agents can also be human. This human-in-the-loop can be beneficial in solving computationally hard problems, e.g., subspace clustering, protein folding, or k-anonymization of health data, where human expertise can help to reduce an exponential search space through heuristic selection of samples. Therefore, what would otherwise be an NP-hard problem, reduces greatly in complexity through the input and the assistance of a human agent involved in the learning phase.},
   keywords = {interactive Mmachine learning, health informatics},
   doi = {10.1007/s40708-016-0042-6},
   url = {http://link.springer.com/article/10.1007/s40708-016-0042-6}
}


@article{Samarati:2001:kAnonymity,
   year = {2001},
   author = {Samarati, Pierangela},
   title = {Protecting respondents identities in microdata release},
   journal = {IEEE Transactions on Knowledge and Data Engineering},
   volume = {13},
   number = {6},
   pages = {1010-1027},
   abstract = {Today’s globally networked society places great demand on the dissemination and sharing of information. While in the past released information was mostly in tabular and statistical form, many situations call today for the release of specific data (microdata). In order to protect the anonymity of the entities (called respondents) to which information refers, data holders often remove or encrypt explicit identifiers such as names, addresses, and phone numbers. De-identifying data, however, provides no guarantee of anonymity. Released information often contains other data, such as race, birth date, sex, and ZIP code, that can be linked to publicly available information to re-identify respondents and inferring information that was not intended for disclosure. In this paper we address the problem of releasing microdata while safeguarding the anonymity of the respondents to which the data refer. The approach is based on the definition of k-anonymity . A table provides k-anonymity if attempts to link explicitly identifying information to its content map the information to at least k entities. We illustrate how k-anonymity can be provided without compromising the integrity (or truthfulness) of the information released by using generalization and suppression techniques. We introduce the concept of minimal generalization that captures the property of the release process not to distort the data more than needed to achieve k-anonymity, and present an algorithm for the computation of such a generalization. We also discuss possible preference policies to choose among different minimal generalizations. },
   keywords = {Privacy, Data Protection},
   doi = {10.1109/69.971193},
   url = {http://spdp.di.unimi.it/papers/tkde_k-anonymity.pdf}
}


@article{HassabisEtAl:2016:Go,
   year = {2016},
   author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
   title = {Mastering the game of Go with deep neural networks and tree search},
   journal = {Nature},
   volume = {529},
   number = {7587},
   pages = {484-489},
   abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
   doi = {10.1038/nature16961}
}



@incollection{NingZhongEtAl:2007:BrainInformatics,
   year = {2007},
   author = {Zhong, N. and Liu, J. M. and Yao, Y. Y. and Wu, J. L. and Lu, S. F. and Qin, Y. L. and Li, K. C. and Wah, B.},
   title = {Web intelligence meets brain informatics},
   booktitle = {Web Intelligence Meets Brain Informatics, Lecture Notes in Artificial Intellience 4845},
   editor = {Zhong, N. and Liu, J. M. and Yao, Y. Y. and Wu, J. L. and Lu, S. F. and Li, K. C.},
   publisher = {Springer},
   address = {Berlin},
   pages = {1-31},
   abstract = {In this chapter, we outline a vision of Web Intelligence (WI) research from the viewpoint of Brain Informatics (BI), a new interdisciplinary field that systematically studies the mechanisms of human information processing from both the macro and micro viewpoints by combining experimental cognitive neuroscience with advanced information technology. BI studies human brain from the viewpoint of informatics (i.e., human brain is an information processing system) and uses informatics (i.e., WI centric information technology) to support brain science study. Advances in instrumentation, e.g., based on fMRI and information technologies offer more opportunities for research in both Web intelligence and brain sciences. Further understanding of human intelligence through brain sciences fosters innovative Web intelligence research and development. WI portal techniques provide a powerful new platform for brain sciences. The synergy between WI and BI advances our ways of analyzing and understanding of data, knowledge, intelligence, and wisdom, as well as their interrelationships, organizations, and creation processes. Web intelligence is becoming a central field that revolutionizes information technologies and artificial intelligence to achieve human-level Web intelligence.}
}

@article{BudgeEtAl:2015:crowdsourcingMedicine,
   year = {2015},
   author = {Jane Budge, Eleanor and Maria Tsoti, Sandra and James Howgate, Daniel and Sivakumar, Shivan and Jalali, Morteza},
   title = {Collective intelligence for translational medicine: Crowdsourcing insights and innovation from an interdisciplinary biomedical research community},
   journal = {Annals of Medicine},
   volume = {47},
   number = {7},
   abstract = {Translational medicine bridges the gap between discoveries in biomedical science and their safe and effective clinical application. Despite the gross opportunity afforded by modern research for unparalleled advances in this field, the process of translation remains protracted. Efforts to expedite science translation have included the facilitation of interdisciplinary collaboration within both academic and clinical environments in order to generate integrated working platforms fuelling the sharing of knowledge, expertise, and tools to align biomedical research with clinical need. However, barriers to scientific translation remain, and further progress is urgently required. Collective intelligence and crowdsourcing applications offer the potential for global online networks, allowing connection and collaboration between a wide variety of fields. This would drive the alignment of biomedical science with biotechnology, clinical need, and patient experience, in order to deliver evidence-based innovation which can revolutionize medical care worldwide. Here we discuss the critical steps towards implementing collective intelligence in translational medicine using the experience of those in other fields of science and public health. Key Messages The scientific translation of biomedical research into clinical applications is protracted, despite the mass opportunity afforded by modern science. Barriers to translational medicine exist as a result of the impracticalities of research, organizational hurdles, and lack of an interdisciplinary workforce. Collective intelligence and crowdsourcing offer the potential to expedite the translational process by providing a platform upon which interdisciplinary workforces can communicate and collaborate, aligning biomedical research with clinical need revolutionizing health care worldwide.},
   doi = {10.3109/07853890.2015.1091945}
}


@article{ZhaoKosorokZeng:2009:RLcancerTrials,
   year = {2009},
   author = {Zhao, Yufan and Kosorok, Michael R and Zeng, Donglin},
   title = {Reinforcement learning design for cancer clinical trials},
   journal = {Statistics in medicine},
   volume = {28},
   number = {26},
   pages = {3294-3315},
   abstract = {life-threatening diseases such as cancer. A temporal-difference learning method called Q-learning is utilized that involves learning an optimal policy from a single training set of finite longitudinal patient trajectories. Approximating the Q-function with time-indexed parameters can be achieved by using support vector regression or extremely randomized trees. Within this framework, we demonstrate that the procedure can extract optimal strategies directly from clinical data without relying on the identification of any accurate mathematical models, unlike approaches based on adaptive design. We show that reinforcement learning has tremendous potential in clinical research because it can select actions that improve outcomes by taking into account delayed effects even when the relationship between actions and outcomes is not fully known. To support our claims, the methodology's practical utility is illustrated in a simulation analysis. In the immediate future, we will apply this general strategy to studying and identifying new treatments for advanced metastatic stage IIIB/IV non-small cell lung cancer, which usually includes multiple lines of chemotherapy treatment. Moreover, there is significant potential of the proposed methodology for developing personalized treatment strategies in other cancers, in cystic fibrosis, and in other life-threatening diseases.},
   doi = {10.1002/sim.3720}
}


@article{LakeSalakTenenbaum:2015:ConceptLearning,
   year = {2015},
   author = {Lake, Brenden M. and Salakhutdinov, Ruslan and Tenenbaum, Joshua B.},
   title = {Human-level concept learning through probabilistic program induction},
   journal = {Science},
   volume = {350},
   number = {6266},
   pages = {1332-1338},
   abstract = {People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms—for action, imagination, and explanation. We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world’s alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches. We also present several “visual Turing tests” probing the model’s creative generalization abilities, which in many cases are indistinguishable from human behavior.},
   doi = {10.1126/science.aab3050}
}

@incollection{HolzingerEtAl:2014:TextMining,
   year = {2014},
   author = {Holzinger, Andreas and Schantl, Johannes and Schroettner, Miriam and Seifert, Christin and Verspoor, Karin},
   title = {Biomedical Text Mining: State-of-the-Art, Open Problems and Future Challenges},
   booktitle = {Interactive Knowledge Discovery and Data Mining in Biomedical Informatics, Lecture Notes in Computer Science LNCS 8401},
   editor = {Holzinger, Andreas and Jurisica, Igor},
   publisher = {Springer },
   address = {Berlin Heidelberg},
   volume = {8401},
   pages = {271-300},
   abstract = {Text is a very important type of data within the biomedical domain. For example, patient records contain large amounts of text which has been entered in a non-standardized format, consequently posing a lot of challenges to processing of such data. For the clinical doctor the written text in the medical findings is still the basis for decision making – neither images nor multimedia data. However, the steadily increasing volumes of unstructured information need machine learning approaches for data mining, i.e. text mining. This paper provides a short, concise overview of some selected text mining methods, focusing on statistical methods, i.e. Latent Semantic Analysis, Probabilistic Latent Semantic Analysis, Latent Dirichlet Allocation, Hierarchical Latent Dirichlet Allocation, Principal Component Analysis, and Support Vector Machines, along with some examples from the biomedical domain. Finally, we provide some open problems and future challenges, particularly from the clinical domain, that we expect to stimulate future research.},
   doi = {10.1007/978-3-662-43968-5_16}
}


@article{Hofmann:2001:PLSA,
   year = {2001},
   author = {Hofmann, Thomas},
   title = {Unsupervised learning by probabilistic latent semantic analysis},
   journal = {Machine learning},
   volume = {42},
   number = {1-2},
   pages = {177-196},
   abstract = {This paper presents a novel statistical method for factor analysis of binary and count data which is closely related to a technique known as Latent Semantic Analysis. In contrast to the latter method which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed technique uses a generative latent class model to perform a probabilistic mixture decomposition. This results in a more principled approach with a solid foundation in statistical inference. More precisely, we propose to make use of a temperature controlled version of the Expectation Maximization algorithm for model fitting, which has shown excellent performance in practice. Probabilistic Latent Semantic Analysis has many applications, most prominently in information retrieval, natural language processing, machine learning from text, and in related areas. The paper presents perplexity results for different types of text and linguistic data collections and discusses an application in automated document indexing. The experiments indicate substantial and consistent improvements of the probabilistic method over standard Latent Semantic Analysis.}
}

@incollection{FahlmannHinton:1983:MassiveParallelism,
   year = {1983},
   author = {Fahlman, Scott E and Hinton, Geoffrey E and Sejnowski, Terrence J},
   title = {Massively parallel architectures for Al: NETL, THISTLE, and BOLTZMANN machines},
   booktitle = {AAAI-83},
   editor = {Genesereth, Michael R.},
   publisher = {AAAI},
   address = {Washington, DC},
   pages = {109-113},
   abstract = {It is becoming increasingly apparent that some aspects of intelligent behavior require enormous computational power and that some sort of massively parallel computing architecture is the most plausible way to deliver such power. Parallelism, rather than raw speed of the computing elements. seems to be the way that the brain gets such jobs done. But even if the need for massive parallelism is admitted, there is still the question of what kind of parallel architecture best fits the needs of various AI tasks. In this paper we will attempt to isolate a number of basic computational tasks that an intelligent system must perform. We will describe several families of massively parallel computing architectures, and we will see which of these computational tasks can be handled by each of these families. In particular, we will describe a new architecture, which we call the Boltzmann machine, whose abilities appear to include a number of tasks that are inefficient or impossible on the other architectures.}
}


@book{Hubel:1995:EyeBrainVision,
   year = {1995},
   author = {Hubel, David H and Wensveen, Janice and Wick, Bruce},
   title = {Eye, brain, and vision},
   publisher = {Scientific American Library},
   address = {New York}
}


@article{Barnard:1958:OnBayes,
   year = {1958},
   author = {Barnard, George A and Bayes, Thomas},
   title = {Studies in the history of probability and statistics: IX. Thomas Bayes's essay towards solving a problem in the doctrine of chances},
   journal = {Biometrika},
   volume = {45},
   number = {3/4},
   pages = {293-315},
   doi = {10.2307/2333180},
   url = {http://www.jstor.org/stable/2333180}
}


@article{1763:BayesOriginal,
   year = {1763},
   author = {Bayes, Thomas},
   title = {An Essay towards solving a Problem in the Doctrine of Chances (Posthumous communicated by Richard Price)},
   journal = {Philosophical Transactions},
   volume = {53},
   pages = {370-418}
}

@book{HastieTibshiraniFriedman:2009:ElementsOfstatisticalLearning,
   year = {2009},
   author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
   title = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Second Edition},
   publisher = {Springer},
   address = {New York},
   abstract = {The field of Statistics is constantly challenged by the problems that science and industry brings to its door. In the early days, these problems often came from agricultural and industrial experiments and were relatively small in scope. With the advent of computers and the information age, statistical problems have exploded both in size and complexity. Challenges in the areas of data storage, organization and searching have led to the new field of “data mining”; statistical and computational problems in biology and medicine have created “bioinformatics.” Vast amounts of data are being generated in many fields, and the statistician’s job is to make sense of it all: to extract important patterns and trends, and understand “what the data says.” We call this learning from data. The challenges in learning from data have led to a revolution in the statistical sciences. Since computation plays such a key role, it is not surprising that much of this new development has been done by researchers in other fields such as computer science and engineering. The learning problems that we consider can be roughly categorized as either supervised or unsupervised. In supervised learning, the goal is to predict the value of an outcome measure based on a number of input measures; in unsupervised learning, there is no outcome measure, and the goal is to describe the associations and patterns among a set of input measures.},
   keywords = {Machine learning},
   doi = {10.1007/978-0-387-84858-7}
}

@book{Murphy:2012:MLbook,
   year = {2012},
   author = {Murphy, Kevin P},
   title = {Machine learning: a probabilistic perspective},
   publisher = {MIT press},
   address = {Cambridge (MA)},
   abstract = {This books adopts the view that the best way to make machines that can learn from data is to use the tools of probability theory, which has been the mainstay of statistics and engineering for centuries. Probability theory can be applied to any problem involving uncertainty. In machine learning, uncertainty comes in many forms: what is the best prediction (or decision) given some data? what is the best model given some data? what measurement should I perform next? etc. The systematic application of probabilistic reasoning to all inferential problems, including inferring parameters of statistical models, is sometimes called a Bayesian approach. However, this term tends to elicit very strong reactions (either positive or negative, depending on who you ask), so we prefer the more neutral term “probabilistic approach”. Besides, we will often use techniques such as maximum likelihood estimation, which are not Bayesian methods, but certainly fall within the probabilistic paradigm.},
   url = {http://www.cs.ubc.ca/~murphyk/MLbook/index.html}
}


@inproceedings{LiEtAl:2007:t-closeness,
   year = {2007},
   author = {Li, Ninghui and Li, Tiancheng and Venkatasubramanian, Suresh},
   title = {t-closeness: Privacy beyond k-anonymity and l-diversity},
   booktitle = {IEEE 23rd International Conference on Data Engineering, ICDE 2007},
   publisher = {IEEE},
   pages = {106-115},
   abstract = {The k-anonymity privacy requirement for publishing microdata requires that each equivalence class (i.e., a set of records that are indistinguishable from each other with respect to certain "identifying" attributes) contains at least k records. Recently, several authors have recognized that k-anonymity cannot prevent attribute disclosure. The notion of l-diversity has been proposed to address this; l-diversity requires that each equivalence class has at least l well-represented values for each sensitive attribute. In this paper we show that l-diversity has a number of limitations. In particular, it is neither necessary nor sufficient to prevent attribute disclosure. We propose a novel privacy notion called t-closeness, which requires that the distribution of a sensitive attribute in any equivalence class is close to the distribution of the attribute in the overall table (i.e., the distance between the two distributions should be no more than a threshold t). We choose to use the earth mover distance measure for our t-closeness requirement. We discuss the rationale for t-closeness and illustrate its advantages through examples and experiments.},
   doi = {10.1109/ICDE.2007.367856}
}


@article{MachanavajjhalaEtAl:2007:l-Diversity,
   year = {2007},
   author = {Machanavajjhala, Ashwin and Kifer, Daniel and Gehrke, Johannes and Venkitasubramaniam, Muthuramakrishnan},
   title = {l-diversity: Privacy beyond k-anonymity},
   journal = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
   volume = {1},
   number = {1},
   pages = {1-52},
   abstract = {Publishing data about individuals without revealing sensitive information about them is an important problem. In recent years, a new definition of privacy called k-anonymity has gained popularity. In a k-anonymized dataset, each record is indistinguishable from at least k − 1 other records with respect to certain identifying attributes. In this article, we show using two simple attacks that a k-anonymized dataset has some subtle but severe privacy problems. First, an attacker can discover the values of sensitive attributes when there is little diversity in those sensitive attributes. This is a known problem. Second, attackers often have background knowledge, and we show that k-anonymity does not guarantee privacy against attackers using background knowledge. We give a detailed analysis of these two attacks, and we propose a novel and powerful privacy criterion called ℓ-diversity that can defend against such attacks. In addition to building a formal foundation for ℓ-diversity, we show in an experimental evaluation that ℓ-diversity is practical and can be implemented efficiently.},
   doi = {10.1145/1217299.1217302}
}

@article{Sweeney:2002:k-Anonymity,
   year = {2002},
   author = {Sweeney, Latanya},
   title = {Achieving k-anonymity privacy protection using generalization and suppression},
   journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
   volume = {10},
   number = {5},
   pages = {571-588},
   abstract = {Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k-anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, μ-Argus and k-Similar provide guarantees of privacy protection.},
   keywords = {Data anonymity; data privacy; re-identification; data fusion; privacy},
   doi = {10.1142/S0218488502001648 },
   url = {http://www.worldscientific.com/doi/abs/10.1142/S0218488502001648}
}


@article{AwastiBalcanVoevodski:2014:InteractiveClustering,
   year = {2014},
   author = {Awasthi, Pranjal and Balcan, Maria-Florina and Voevodski, K},
   title = {Local algorithms for interactive clustering},
   journal = { Proceedings of the 31th International Conference on Machine Learning},
   pages = {550-558}
}

@incollection{BalcanBlum:2008:ClusteringInteractive,
   year = {2008},
   author = {Balcan, Maria-Florina and Blum, Avrim},
   title = {Clustering with Interactive Feedback},
   booktitle = {Algorithmic Learning Theory: 19th International Conference, ALT 2008, Budapest, Hungary, October 13-16, 2008. Proceedings},
   editor = {Freund, Yoav and Györfi, László and Turán, György and Zeugmann, Thomas},
   publisher = {Springer Berlin Heidelberg},
   address = {Berlin, Heidelberg},
   pages = {316-328},
   doi = {10.1007/978-3-540-87987-9_27}
}

@article{BushMosteller:1951:SimpleLearning,
   year = {1951},
   author = {Bush, Robert R and Mosteller, Frederick},
   title = {A mathematical model for simple learning},
   journal = {Psychological review},
   volume = {58},
   number = {5},
   pages = {313-323},
   doi = {http://dx.doi.org/10.1037}
}

@article{Thurstone:1927:ComparativeJudgement,
   year = {1927},
   author = {Thurstone, L. L.},
   title = {A law of comparative judgment},
   journal = {Psychological Review},
   volume = {34},
   number = {4},
   pages = {273-286},
   doi = {10.1037/h0070288}
}

@book{Hunt:1962:conceptLearning,
   year = {1962},
   author = {Hunt, Earl B},
   title = {Concept learning: An information processing problem},
   publisher = {John Wiley \& Sons},
   address = {Hoboken (NJ)},
   abstract = {The ability to think in terms of abstractions is one of the most powerful tools man possesses. It is literally true that we never step into the same river twice; every situation is in some sense unique. Yet we manage to order our experience into coherent categories by defining a given situation as a member of that collection of situations for which responses x, y, etc. are appropriate. We classify. Classification is not a passive process. Tests must be made to determine whether the present situation contains certain elements or whether it can be described in a particular way. The results of these tests provide the information we use to guide the classifying act. But how do we develop rules for testing? This is the question to which the present research has been addressed. Understanding how humans learn abstractions is essential to the understanding of human thought. This monograph has been organized with a definite view in mind. We wished to present a unified picture of current research and thought on the topic of concept learning. It was felt that workers in several disciplines, proceeding quite independently of each other, have made substantial contributions to the field. The psychological study of concept learning has undergone a resurgence in the past few years. At the same time, workers interested in the design of artificial intelligence systems have faced the problem of how concepts ought to be learned. A major purpose of this text is to present a synthesis of the work in these separate but related areas. Concepts are essentially definitions in symbolic logic. Therefore, their role in logic should be considered. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
   doi = {http://dx.doi.org/10.1037/13135-001}
}

@incollection{HollandEsterKiessling:2003:PreferenceMining,
   year = {2003},
   author = {Holland, S. and Ester, M. and Kiessling, W.},
   title = {Preference Mining: A novel approach on mining user preferences for personalized applications},
   booktitle = {Knowledge Discovery in Databases: PKDD 2003, Proceedings LNAI},
   editor = {Lavrac, N. and Gamberger, D. and Todorovski, L. and Blockeel, H.},
   publisher = {Springer-Verlag Berlin},
   address = {Berlin},
   volume = {2838},
   pages = {204-216},
   abstract = {Advanced personalized e-applications require comprehensive knowledge about their user's likes and dislikes in order to provide individual product recommendations, personal customer advice and custom-tailored product offers. In our approach we model such preferences as strict partial orders with "A is better than B" semantics, which has been proven to be very suitable in various e-applications. In this paper we present novel Preference Mining techniques for detecting strict partial order preferences in user log data. The main advantage of our approach is the semantic expressiveness of the Preference Mining results. Experimental evaluations prove the effectiveness and efficiency of our algorithms. Since the Preference Mining implementation uses sophisticated SQL statements to execute all data-intensive operations on database layer, our algorithms scale well even for large log data sets. With our approach personalized e-applications can gain valuable knowledge about their customers' preferences, which is essential for a qualified customer service.}
}

@book{FuernkranzHuellermeier2010:PL,
   year = {2010},
   author = {F{\"u}rnkranz, Johannes and H{\"u}llermeier, Eyke},
   title = {Preference learning},
   publisher = {Springer},
   address = {Berlin Heidelberg},
   abstract = {This introduction gives a brief overview of the field of preference learning and, along the way, tries to establish a unified terminology. Special emphasis will be put on learning to rank, which is by now one of the most extensively studied problem tasks in preference learning and also prominently represented in this book. We propose a categorization of ranking problems into object ranking, instance ranking, and label ranking. Moreover, we introduce these scenarios in a formal way, discuss different ways in which the learning of ranking functions can be approached, and explain how the contributions collected in this book relate to this categorization. Finally, we also highlight some important applications of preference learning methods}
}


@inproceedings{Agarwal:2005:LearningToRank,
   year = {2005},
   author = {Agarwal, Shivani and Cortes, Corinna and Herbrich, Ralf},
   title = {Learning to rank},
   booktitle = {NIPS Workshop},
   editor = {Weiss, Y. and Schölkopf, B. and Platt, J.C.},
}

@article{Trotman:2005:LearningToRank,
   year = {2005},
   author = {Trotman, Andrew},
   title = {Learning to rank},
   journal = {Information Retrieval},
   volume = {8},
   number = {3},
   pages = {359-381}
}

@book{Liu:2011:LearningToRank,
   year = {2011},
   author = {Liu, Tie-Yan},
   title = {Learning to Rank for Information Retrieval},
   publisher = {Springer},
   address = {Berlin, Heidelberg},
   abstract = {Preference learning is a subfield in machine learning in which the goal is to learn a predictive preference model from observed preference information. In the view of supervised learning, preference learning trains on a set of items which have preferences toward labels or other items and predicts the preferences for all items.},
   doi = {10.1007/978-3-642-14267-3_1}
}


@inproceedings{SuayChernova:2011:iRL,
   year = {2011},
   author = {Suay, Halit Bener and Chernova, Sonia},
   title = {Effect of human guidance and state space size on interactive reinforcement learning},
   booktitle = {20th IEEE International Symposium on Robot and Human Interactive Communication},
   publisher = {IEEE},
   pages = {1-6},
   abstract = {The Interactive Reinforcement Learning algorithm enables a human user to train a robot by providing rewards in response to past actions and anticipatory guidance to guide the selection of future actions. Past work with software agents has shown that incorporating user guidance into the policy learning process through Interactive Reinforcement Learning significantly improves the policy learning time by reducing the number of states the agent explores. We present the first study of Interactive Reinforcement Learning in realworld robotic systems. We report on four experiments that study the effects that teacher guidance and state space size have on policy learning performance. We discuss modifications made to apply Interactive Reinforcement Learning to a realworld system and show that guidance significantly reduces the learning rate, and that its positive effects increase with state space size.}
}


@article{YangEtAl:2014:Multi-Agent-iRL,
   year = {2014},
   author = {Yang, M. and Yang, Y. X. and Wang, W. and Ding, H. Y. and Chen, J.},
   title = {Multiagent-Based Simulation of Temporal-Spatial Characteristics of Activity-Travel Patterns Using Interactive Reinforcement Learning},
   journal = {Mathematical Problems in Engineering},
   abstract = {We propose a multiagent-based reinforcement learning algorithm, in which the interactions between travelers and the environment are considered to simulate temporal-spatial characteristics of activity-travel patterns in a city. Road congestion degree is added to the reinforcement learning algorithm as a medium that passes the influence of one traveler's decision to others. Meanwhile, the agents used in the algorithm are initialized from typical activity patterns extracted from the travel survey diary data of Shangyu city in China. In the simulation, both macroscopic activity-travel characteristics such as traffic flow spatial-temporal distribution and microscopic characteristics such as activity-travel schedules of each agent are obtained. Comparing the simulation results with the survey data, we find that deviation of the peak-hour traffic flow is less than 5%, while the correlation of the simulated versus survey location choice distribution is over 0.9.},
   doi = {10.1155/2014/951367}
}



@inproceedings{ThomazEtAl:2005:interactiveRL,
   year = {2005},
   author = {Thomaz, Andrea and Hoffman, Guy and Breazeal, Cynthia},
   title = {Real-time interactive reinforcement learning for robots},
   booktitle = {AAAI 2005 workshop on human comprehensible machine learning},
   editor = {Oblinger, Dan and Lau, Tessa and Gil, Yolanda and Bauer, Mathias},
   publisher = {AAAI Press, Menlo Park, California},
   pages = {9-13},

}

@article{Szepesvari:2010:RL-algorithms,
   year = {2010},
   author = {Szepesvári, Csaba},
   title = {Algorithms for reinforcement learning},
   journal = {Synthesis lectures on artificial intelligence and machine learning},
   volume = {4},
   number = {1},
   pages = {1-103}
}



@inproceedings{SamaratiSweeney:1998:kAnonymity,
   year = {1998},
   author = {Samarati, Pierangela and Sweeney, Latanya},
   title = {Generalizing data to provide anonymity when disclosing information},
   booktitle = {PODS '98 17th ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems},
   editor = {Mendelzon, Alberto O. and Paredaens, Jan},
   publisher = {ACM},
   pages = {188},
   doi = {10.1145/275487.275508}
}


@article{TaylorStone:2009:TransferLearning,
   year = {2009},
   author = {Taylor, Matthew E and Stone, Peter},
   title = {Transfer learning for reinforcement learning domains: A survey},
   journal = {The Journal of Machine Learning Research},
   volume = {10},
   pages = {1633-1685},
   abstract = {The reinforcement learning paradigm is a popular way to address problems that have only limited environmental feedback, rather than correctly labeled examples, as is common in other machine learning contexts. While significant progress has been made to improve learning in a single task, the idea of transfer learning has only recently been applied to reinforcement learning tasks. The core idea of transfer is that experience gained in learning to perform one task can help improve learning performance in a related, but different, task. In this article we present a framework that classifies transfer learning methods in terms of their capabilities and goals, and then use it to survey the existing literature, as well as to suggest future directions for transfer learning work.}
}


@article{WeinbergerLawrence:2009:MetricLearning,
   year = {2009},
   author = {Weinberger, Kilian Q and Saul, Lawrence K},
   title = {Distance metric learning for large margin nearest neighbor classification},
   journal = {The Journal of Machine Learning Research},
   volume = {10},
   pages = {207-244},
   abstract = {The accuracy of k-nearest neighbor (kNN) classification depends significantly on the metric used to compute distances between different examples. In this paper, we show how to learn a Mahalanobis distance metric for kNN classification from labeled examples. The Mahalanobis metric can equivalently be viewed as a global linear transformation of the input space that precedes kNN classification using Euclidean distances. In our approach, the metric is trained with the goal that the k-nearest neighbors always belong to the same class while examples from different classes are separated by a large margin. As in support vector machines (SVMs), the margin criterion leads to a convex optimization based on the hinge loss. Unlike learning in SVMs, however, our approach requires no modification or extension for problems in multiway (as opposed to binary) classification. In our framework, the Mahalanobis distance metric is obtained as the solution to a semidefinite program. On several data sets of varying size and difficulty, we find that metrics trained in this way lead to significant improvements in kNN classification. Sometimes these results can be further improved by clustering the training examples and learning an individual metric within each cluster. We show how to learn and combine these local metrics in a globally integrated manner.}
}



@inproceedings{EvgeniouPontil:2004:RegularizedMTL,
   year = {2004},
   author = {Evgeniou, Theodoros and Pontil, Massimiliano},
   title = {Regularized multi-task learning},
   booktitle = {Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
   publisher = {ACM},
   pages = {109-117},
   abstract = {Past empirical work has shown that learning multiple related tasks from data simultaneously can be advantageous in terms of predictive performance relative to learning these tasks independently. In this paper we present an approach to multi–task learning based on the minimization of regularization functionals similar to existing ones, such as the one for Support Vector Machines (SVMs), that have been successfully used in the past for single–task learning. Our approach allows to model the relation between tasks in terms of a novel kernel function that uses a task–coupling parameter. We implement an instance of the proposed approach similar to SVMs and test it empirically using simulated as well as real data. The experimental results show that the proposed method performs better than existing multi–task learning methods and largely outperforms single–task learning using SVMs. }
}

@article{Baxter:2000:InductiveBiasLearning,
   year = {2000},
   author = {Baxter, Jonathan},
   title = {A model of inductive bias learning},
   journal = {Journal of Artificial Intelligence Research},
   volume = {12},
   pages = {149-198},
   abstract = {A major problem in machine learning is that of inductive bias: how to choose a learner’ s hypothesis space so that it is large enough to contain a solution to the problem being learnt, yet small enough to ensure reliable generalization from reasonably-sized training sets. T ypically such bias is supplied by hand through the skill and insights of experts. In this paper a model for automatically learning bias is investigated. The central assumption of the model is that the learner is embedded within an envir onment of related learning tasks. Within such an environment the learner can sample from multiple tasks, and hence it can search for a hypothesis space that contains good solutions to many of the problems in the environment. Under certain restrictions on the set of all hypothesis spaces available to the learner, we show that a hypothesis space that performs well on a sufficiently large number of training tasks will also perform well when learning novel tasks in the same environment. Explicit bounds are also derived demonstrating that learning multiple tasks within an environment of related tasks can potentially give much better generalization than learning a single task. }
}


@article{Valiant:1984:TheoryOfTheLearnable,
   year = {1984},
   author = {Valiant, Leslie G},
   title = {A theory of the learnable},
   journal = {Communications of the ACM},
   volume = {27},
   number = {11},
   pages = {1134-1142},
   abstract = {Humans  appear  to  be  able  to  learn  new  concepts  without  needing  to  be  programmed  explicitly  in  any  conventional  sense.  In  this  paper  we  regard  learning  as  the  phenomenon  of knowledge  acquisition  in  the  absence  of  explicit  programming.  We give  a  precise  methodology  for  studying  this  phenomenon  from  a  computational  viewpoint.  It  consists  of choosing  an  appropriate  information  gathering  mechanism,  the  learning  protocol,  and  exploring  the  class  of  concepts  that  can  be  learned  using  it  in  a  reasonable  (polynomial)  number  of steps.  Although  inherent  algorithmic  complexity  appears  to  set  serious  limits  to  the  range  of  concepts  that  can  be  learned,  we  show  that  there  are  some  important  nontrivial  classes  of propositional  concepts  that  can  be  learned  in  a  realistic  sense.},
   doi = {10.1145/1968.1972}
}

@article{GoodfellowBengio:2015:CatastrophicForgetting,
   year = {2015},
   author = {Goodfellow, Ian J and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
   title = {An empirical investigation of catastrophic forgeting in gradient-based neural networks},
   journal = {arXiv:1312.6211v3},
   abstract = {Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models "forget" how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm--the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests the choice of activation function should always be cross-validated. }
}

@article{French:1999:catastrophicforgetting,
   year = {1999},
   author = {French, Robert M.},
   title = {Catastrophic forgetting in connectionist networks},
   journal = {Trends in Cognitive Sciences},
   volume = {3},
   number = {4},
   pages = {128-135},
   abstract = {All natural cognitive systems, and, in particular, our own, gradually forget previously learned information. Plausible models of human cognition should therefore exhibit similar patterns of gradual forgetting of old information as new information is acquired. Only rarely does new learning in natural cognitive systems completely disrupt or erase previously learned information; that is, natural cognitive systems do not, in general, forget 'catastrophically'. Unfortunately, though, catastrophic forgetting odes occur under certain circumstances in distributed connectionist networks. The very features that give these networks their remarkable abilities to generalize, to function in the presence of degraded input, ans so on, are found to be the root cause of catastrophic forgetting. The challenge in this field is to discover how to keep the advantages of distributed connectionist networks while avoiding the problem of catastrophic forgetting. In this article the causes, consequences and numerous solutions to the problem of catastrophic forgetting in neural networks are examined. The review will consider how the brain might have overcome this problem and will also explore the consequences of this solution for distributed connectionist networks.},
   keywords = {recognition memory
models
representations},
   doi = {10.1016/s1364-6613(99)01294-2}
}


@incollection{McCloskeyCohen:1989:catastrophicInterference,
   year = {1989},
   author = {McCloskey, Michael and Cohen, Neal J},
   title = {Catastrophic interference in connectionist networks: The sequential learning problem},
   booktitle = {The Psychology of Learning and Motivation, Volume 24},
   editor = {Bower, G. H.},
   publisher = {Academic Press},
   address = {San Diego (CA)},
   pages = {109-164}
}


@article{NergizClifton:2010:Delta-Presence,
   year = {2010},
   author = {Nergiz, M. E. and Clifton, C.},
   title = {delta-Presence without Complete World Knowledge},
   journal = {IEEE Transactions on Knowledge and Data Engineering},
   volume = {22},
   number = {6},
   pages = {868-883},
   abstract = {Advances in information technology, and its use in research, are increasing both the need for anonymized data and the risks of poor anonymization. In [1], we presented a new privacy metric, delta-presence, that clearly links the quality of anonymization to the risk posed by inadequate anonymization. It was shown that existing anonymization techniques are inappropriate for situations where delta-presence is a good metric (specifically, where knowing an individual is in the database poses a privacy risk). This article addresses a practical problem with [1], extending to situations where the data anonymizer is not assumed to have complete world knowledge. The algorithms are evaluated in the context of a real-world scenario, demonstrating practical applicability of the approach.},
   keywords = {k-Anonymity
privacy
delta presence
medical databases},
   doi = {10.1109/tkde.2009.125}
}


@inproceedings{SturmEtAl:2015:MedicalKnowledgeOmics,
   year = {2015},
   author = {Sturm, Werner and Schreck, Tobias and Holzinger, Andreas and Ullrich, Torsten},
   title = {Discovering Medical Knowledge Using Visual Analytics – a survey on methods for systems biology and omics data},
   booktitle = {Eurographics Workshop on Visual Computing for Biology and Medicine (2015)},
   editor = {B{\"u}hler, Katja and Linsen, Lars and John, Nigel W.},
   publisher = {Eurographics EG},
   pages = {71-81},
   abstract = {Due to advanced technologies, the amount of biomedical data has been increasing drastically. Such large data sets might be obtained from hospitals, medical practices or laboratories and can be used to discover unknown knowledge and to find and reflect hypotheses. Based on this fact, knowledge discovery systems can support experts to make further decisions, explore the data or to predict future events. To analyze and communicate such a vast amount of information to the user, advanced techniques such as knowledge discovery and information visualization are necessary. Visual analytics combines these fields and supports users to integrate domain knowledge into the knowledge discovery process. This article gives a state-of-the-art overview on visual analytics reseach with a focus on the biomedical domain, systems biology and omics data.
Categories and Subject Descriptors according to ACM CCS: H.1.2 [Information Systems]: User/Machine Systems—Human information processing J.3 [Computer Applications]: Life and Medical Sciences—Biology and genetics J.3 [Computer Applications]: Life and Medical Sciences—Medical information systems},
   doi = {DOI: 10.2312/vcbm.20151210}
}




@article{KokVlassis:2006:MAS-JMLR,
   year = {2006},
   author = {Kok, Jelle R and Vlassis, Nikos},
   title = {Collaborative multiagent reinforcement learning by payoff propagation},
   journal = {The Journal of Machine Learning Research},
   volume = {7},
   pages = {1789-1828},
   abstract = {In this article we describe a set of scalable techniques for learning the behavior of a group of agents in a collaborative multiagent setting. As a basis we use the framework of coordination graphs of Guestrin, Koller, and Parr (2002a) which exploits the dependencies between agents to decompose the global payoff function into a sum of local terms. First, we deal with the single-state case and describe a payoff propagation algorithm that computes the individual actions that approximately maximize the global payoff function. The method can be viewed as the decision-making analogue of belief propagation in Bayesian networks. Second, we focus on learning the behavior of the agents in sequential decision-making tasks. We introduce different model-free reinforcementlearning techniques, unitedly called Sparse Cooperative Q-learning, which approximate the global action-value function based on the topology of a coordination graph, and perform updates using the contribution of the individual agents to the maximal global action value. The combined use of an edge-based decomposition of the action-value function and the payoff propagation algorithm for efficient action selection, result in an approach that scales only linearly in the problem size. We provide experimental evidence that our method outperforms related multiagent reinforcement-learning methods based on temporal differences.}
}



@incollection{VanDykeEtAl:2007:HybridMultiAgentSystems,
   year = {2007},
   author = {Van Dyke Parunak, H. and Nielsen, Paul and Br{\"u}ckner, Sven and Alonso, Rafael},
   title = {Hybrid Multi-agent Systems: Integrating Swarming and {BDI} Agents},
   booktitle = {Engineering Self-Organising Systems},
   publisher = {Springer},
   address = {Berlin Heidelberg},
   pages = {1-14},
   abstract = {The individual agents that interact in a multi-agent system typically exist along a continuum ranging from heavyweight cognitive agents (often of the “BDI” type) to lightweight agents with limited individual processing (digital ants). Most systems use agents from a single position along this spectrum. We have successfully implemented several systems in which agents of very different degrees of internal sophistication interact with one another. Based on this experience, we identify several different ways in which agents of different kinds can be integrated in a single system, and offer observations and lessons from our experiences.},
   doi = {10.1007/978-3-540-69868-5_1}
}


@incollection{FreundEtAl:2000:HybridSystemHWR,
   year = {2000},
   author = {Freund, Rudolf and Neubauer, Markus and Summerer, Martin and Gruber, Stefan and Schaffer, Juergen and Swoboda, Roland},
   title = {A hybrid system for the recognition of hand-written characters},
   booktitle = {Advances in Pattern Recognition},
   publisher = {Springer},
   address = {Heidelberg},
   pages = {67-76},
   abstract = {In this paper we introduce a new hybrid system for the automated recognition of hand-written characters — we combine the most promising approaches of the last decade, i.e., neural networks and structural/ syntactical analysis methods. The given patterns represent handwritten capital letters and digits stored in arrays. The first part of the hybrid system consists of the implementation of a neural network and yields a rapid and reliable pre-selection of the most probable characters the given pattern may represent. Depending on the quality and the special characteristics of the given pattern a flexible set of characters is communicated to the second part of the hybrid system, the structural analysis module. The final decision is based on the evaluation of the presence of features, being characteristic for a specific character, in the underlying pattern. Basically, the structural analysis module consists of graph controlled array grammar systems using prescribed teams of productions. We describe the main parts of the implemented hybrid system and demonstrate the power of our approach.}
}

@article{WellerMann:1997:ConsensusTheoryMedicalDecisionMaking,
   year = {1997},
   author = {Weller, Susan C and Mann, N Clay},
   title = {Assessing rater performance without a gold standard using consensus theory},
   journal = {Medical Decision Making},
   volume = {17},
   number = {1},
   pages = {71-79}
}


@article{BenediktSwain:1992:ConsensusMethods,
   year = {1992},
   author = {Benediktsson, Jon A and Swain, Philip H},
   title = {Consensus theoretic classification methods},
   journal = {IEEE Transactions on Systems, Man and Cybernetics},
   volume = {22},
   number = {4},
   pages = {688-704}
}



@article{DeGroot:1974:ReachingConsensus,
   year = {1974},
   author = {DeGroot, Morris H},
   title = {Reaching a consensus},
   journal = {Journal of the American Statistical Association},
   volume = {69},
   number = {345},
   pages = {118-121},
   abstract = {Consider  a  group  of  individuals  who  must  act  together  as  a  team  or committee,  and  suppose that  each individual  in  the  group  has his  own subjective probability  distribution  for  the  unknown  value  of  some parameter.  A  model  is  presented  which  describes  how  the  group  might reach agreement  on  a  common subjective probability  distribution for  the  parameter  by  pooling  their  individual  opinions.  The process leading  to  the  consensus is  explicitly  described  and  the  common  distribution  that  is  reached  is  explicitly  determined.  The  model  can  also be  applied to  problems  of  reaching  a consensus when  the  opinion  of each member  of  the  group  is  represented  simply  as a point  estimate  of the  parameter  rather  than  as a  probability  distribution.}
}



@book{Lnych:1996:DistributedAlgorithms,
   year = {1996},
   author = {Lynch, Nancy A},
   title = {Distributed algorithms},
   publisher = {Morgan Kaufmann},
   address = {San Francisco}
}


@article{RocheEtAl:2008:MasEpidemiology,
   year = {2008},
   author = {Roche, B. and Guegan, J. F. and Bousquet, F.},
   title = {Multi-agent systems in epidemiology: a first step for computational biology in the study of vector-borne disease transmission},
   journal = {BMC Bioinformatics},
   volume = {9},
   abstract = {Background: Computational biology is often associated with genetic or genomic studies only. However, thanks to the increase of computational resources, computational models are appreciated as useful tools in many other scientific fields. Such modeling systems are particularly relevant for the study of complex systems, like the epidemiology of emerging infectious diseases. So far, mathematical models remain the main tool for the epidemiological and ecological analysis of infectious diseases, with SIR models could be seen as an implicit standard in epidemiology. Unfortunately, these models are based on differential equations and, therefore, can become very rapidly unmanageable due to the too many parameters which need to be taken into consideration. For instance, in the case of zoonotic and vector-borne diseases in wildlife many different potential host species could be involved in the life-cycle of disease transmission, and SIR models might not be the most suitable tool to truly capture the overall disease circulation within that environment. This limitation underlines the necessity to develop a standard spatial model that can cope with the transmission of disease in realistic ecosystems. Results: Computational biology may prove to be flexible enough to take into account the natural complexity observed in both natural and man-made ecosystems. In this paper, we propose a new computational model to study the transmission of infectious diseases in a spatially explicit context. We developed a multi-agent system model for vector-borne disease transmission in a realistic spatial environment. Conclusion: Here we describe in detail the general behavior of this model that we hope will become a standard reference for the study of vector-borne disease transmission in wildlife. To conclude, we show how this simple model could be easily adapted and modified to be used as a common framework for further research developments in this field.},
   doi = {10.1186/1471-2105-9-435}
}

@article{Sycara:1998:MAS,
   year = {1998},
   author = {Sycara, Katia P},
   title = {Multiagent systems},
   journal = {AI magazine},
   volume = {19},
   number = {2},
   pages = {79},
   abstract = {Agent-based systems technology has generated lots of excitement in recent years because of its promise as a new paradigm for conceptualizing, designing, and implementing software systems. This promise is particularly attractive for creating software that operates in environments that are distributed and open, such as the internet. Currently, the great majority of agent-based systems consist of a single agent. However, as the technology matures and addresses increasingly complex applications, the need for systems that consist of
multiple agents that communicate in a peer-topeer fashion is becoming apparent. Central to the design and effective operation of such multiagent systems (MASs) are a core set of issues and research questions that have been studied over the years by the distributed AI community. In this article, I present some of the critical notions in MASs and the research work that has addressed them. I organize these notions around the concept of problem-solving coherence, which I believe is one of the most critical overall characteristics that an MAS should exhibit.},
   url = {http://aitopics.org/topic/multi-agent-systems}
}



@article{Olfati-Saber2007MultiAgents,
   year = {2007},
   author = {Olfati-Saber, Reza and Fax, J. A. and Murray, R. M.},
   title = {Consensus and cooperation in networked multi-agent systems},
   journal = {Proceedings of the IEEE},
   volume = {95},
   number = {1},
   pages = {215-233},
   abstract = {This paper provides a theoretical framework for analysis of consensus algorithms for multi-agent networked systems with an emphasis on the role of directed information flow, robustness to changes in network topology due to link/node failures, time-delays, and performance guarantees. An overview of basic concepts of information consensus in networks and methods of convergence and performance analysis for the algorithms are provided. Our analysis framework is based on tools from matrix theory, algebraic graph theory, and control theory. we discuss the connections between consensus problem in networked dynamic systems and diverse applications including synchronization of coupled oscillators, flocking, formation control, fast consensus in small-world networks, Markov processes and gossip-based algorithms, load balancing in networks, rendezvous in space, distributed sensor fusion in sensor networks, and belief propagation. We establish direct connections between spectral and structural properties of complex networks and the speed of information diffusion of consensus algorithms. A brief introduction is provided on networked systems with nonlocal information flow that are considerably faster than distributed systems with lattice-type nearest neighbor interactions. Simulation results are presented that demonstrate the role of small-world effects on the speed of consensus algorithms and cooperative control of multivehicle formations.},
   doi = {10.1109/jproc.2006.887293}
}



@article{WilsonDannLucasXing:2015:TheHumanKernel,
   year = {2015},
   author = {Wilson, Andrew Gordon and Dann, Christoph and Lucas, Christopher G and Xing, Eric P},
   title = {The Human Kernel},
   journal = {arXiv preprint arXiv:1510.07389},
   abstract = {Bayesian nonparametric models, such as Gaussian processes, provide a compelling framework for automatic statistical modelling: these models have a high degree of flexibility, and automatically calibrated complexity. However, automating human expertise remains elusive; for example, Gaussian processes with standard kernels struggle on function extrapolation problems that are trivial for human learners. In this paper, we create function extrapolation problems and acquire human responses, and then design a kernel learning framework to reverse engineer the inductive biases of human learners across a set of behavioral experiments. We use the learned kernels to gain psychological insights and to extrapolate in humanlike ways that go beyond traditional stationary and polynomial kernels. Finally, we investigate Occam’s razor in human and Gaussian process based function learning.}
}


@article{Lathrop:1994:ProteinFoldingNPcomplete,
   year = {1994},
   author = {Lathrop, R. H.},
   title = {The Protein Threading Problem with Sequence Amino-Acid Interaction Preferences is NP-Complete},
   journal = {Protein Engineering},
   volume = {7},
   number = {9},
   pages = {1059-1068},
   abstract = {In recent protein structure prediction research there has been a great deal of interest in using amino acid interaction preferences (e.g. contact potentials or potentials of mean force) to align ('thread') a protein sequence to a known structural motif. An important open question is whether a polynomial time algorithm for finding the globally optimal threading is possible. We identify the two critical conditions governing this question: (i) variable-length gaps are admitted into the alignment, and (ii) interactions between amino acids from the sequence are admitted into the score function. We prove that if both these conditions are allowed then the protein threading decision problem (does there exist a threading with a score less than or equal to K?) is NP-complete (in the strong sense, i.e. is not merely a number problem) and the related problem of finding the globally optimal protein threading is NP-hard. Therefore, no polynomial time algorithm is possible (unless P = NP). This result augments existing proofs that the direct protein folding problem is NP-complete by providing the corresponding proof for the 'inverse' protein folding problem. It provides a theoretical basis for understanding algorithms currently in use and indicates that computational strategies from other NP-complete problems may be useful for predictive algorithms.},
   doi = {10.1093/protein/7.9.1059}
}





@article{CooperEtAl:2010:folditNature,
   year = {2010},
   author = {Cooper, Seth and Khatib, Firas and Treuille, Adrien and Barbero, Janos and Lee, Jeehyung and Beenen, Michael and Leaver-Fay, Andrew and Baker, David and Popovic, Zoran},
   title = {Predicting protein structures with a multiplayer online game},
   journal = {Nature},
   volume = {466},
   number = {7307},
   pages = {756-760},
   doi = {10.1038/nature09304}
}


@inproceedings{Aggarwal:2005:kAnonymity,
   year = {2005},
   author = {Aggarwal, Charu C},
   title = {On k-anonymity and the curse of dimensionality},
   booktitle = {Proceedings of the 31st international conference on Very large data bases VLDB},
   pages = {901-909},
   abstract = {In recent years, the wide availability of personal data has made the problem of privacy preserving data mining an important one. A number of methods have recently been proposed for privacy preserving data mining of multidimensional data records. One of the methods for privacy preserving data mining is that of anonymization, in which a record is released only if it is indistinguishable from k other entities in the data. We note that methods such as k-anonymity are highly dependent upon spatial locality in order to effectively implement the technique in a statistically robust way. In high dimensional space the data becomes sparse, and the concept of spatial locality is no longer easy to define from an application point of view. In this paper, we view the k-anonymization problem from the perspective of inference attacks over all possible combinations of attributes. We show that when the data contains a large number of attributes which may be considered quasi-identifiers, it becomes difficult to anonymize the data without an unacceptably high amount of information loss. This is because an exponential number of combinations of dimensions can be used to make precise inference attacks, even when individual attributes are partially specified within a range. We provide an analysis of the effect of dimensionality on k-anonymity methods. We conclude that when a data set contains a large number of attributes which are open to inference attacks, we are faced with a choice of either completely suppressing most of the data or losing the desired level of anonymity. Thus, this paper shows that the curse of high dimensionality also applies to the problem of privacy preserving data mining.}
}


@article{GigerenzerGaissmaier:2011:HeuristicDecisionMaking,
   year = {2011},
   author = {Gigerenzer, G. and Gaissmaier, W.},
   title = {Heuristic Decision Making},
   journal = {Annual Review of Psychology},
   volume = {62},
   pages = {451-482},
   abstract = {As reflected in the amount of controversy, few areas in psychology have undergone such dramatic conceptual changes in the past decade as the emerging science of heuristics. Heuristics are efficient cognitive processes, conscious or unconscious, that ignore part of the information. Because using heuristics saves effort, the classical view has been that heuristic decisions imply greater errors than do "rational" decisions as defined by logic or statistical models. However, for many decisions, the assumptions of rational models are not met, and it is an empirical rather than an a priori issue how well cognitive heuristics function in an uncertain world. To answer both the descriptive question ("Which heuristics do people use in which situations?") and the prescriptive question ("When should people rely on a given heuristic rather than a complex strategy to make better judgments?"), formal models are indispensable. We review research that tests formal models of heuristic inference, including in business organizations, health care, and legal institutions. This research indicates that (a) individuals and organizations often rely on simple heuristics in an adaptive way, and (b) ignoring part of the information can lead to more accurate judgments than weighting and adding all information, for instance for low predictability and small samples. The big future challenge is to develop a systematic theory of the building blocks of heuristics as well as the core capacities and environmental structures these exploit.},
   doi = {10.1146/annurev-psych-120709-145346}
}




@article{AkgulBurakEtAl:2011:cbirExpertInTheLoop,
   year = {2011},
   author = {Akgul, C. B. and Rubin, D. L. and Napel, S. and Beaulieu, C. F. and Greenspan, H. and Acar, B.},
   title = {Content-Based Image Retrieval in Radiology: Current Status and Future Directions},
   journal = {Journal of Digital Imaging},
   volume = {24},
   number = {2},
   pages = {208-222},
   abstract = {Diagnostic radiology requires accurate interpretation of complex signals in medical images. Content-based image retrieval (CBIR) techniques could be valuable to radiologists in assessing medical images by identifying similar images in large archives that could assist with decision support. Many advances have occurred in CBIR, and a variety of systems have appeared in nonmedical domains; however, permeation of these methods into radiology has been limited. Our goal in this review is to survey CBIR methods and systems from the perspective of application to radiology and to identify approaches developed in nonmedical applications that could be translated to radiology. Radiology images pose specific challenges compared with images in the consumer domain; they contain varied, rich, and often subtle features that need to be recognized in assessing image similarity. Radiology images also provide rich opportunities for CBIR: rich metadata about image semantics are provided by radiologists, and this information is not yet being used to its fullest advantage in CBIR systems. By integrating pixel-based and metadata-based image feature analysis, substantial advances of CBIR in medicine could ensue, with CBIR systems becoming an important tool in radiology practice.},
   keywords = {Content-based image retrieval},
   doi = {10.1007/s10278-010-9290-9}
}

%Attention: this paper has not been published
@inproceedings{MaoProcaccia:2011:HumanMultiAgentSystem,
   year = {2011},
   author = {Mao, Andrew and Parkes, David C and Procaccia, Ariel D and Zhang, Haoqi},
   title = {Human computation and multiagent systems: an algorithmic perspective},
   booktitle = {Proceedings of the 25thh AAAI conference on artificial intelligence},
   editor = {Bugard, Wolfram and Roth, Dan}
}


@article{LeCunBengioHinton:2015:DeepLearningNature,
   year = {2015},
   author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
   title = {Deep learning},
   journal = {Nature},
   volume = {521},
   number = {7553},
   pages = {436-444},
   abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
   doi = {10.1038/nature14539}
}

@article{Ghahramani2015:ProbabilisticMLnature,
   year = {2015},
   author = {Ghahramani, Zoubin},
   title = {Probabilistic machine learning and artificial intelligence},
   journal = {Nature},
   volume = {521},
   number = {7553},
   pages = {452-459},
   abstract = {How can a machine learn from experience? Probabilistic modelling provides a framework for understanding what learning is, and has therefore emerged as one of the principal theoretical and practical approaches for designing machines that learn from data acquired through experience. The probabilistic framework, which describes how to represent and manipulate uncertainty about models and predictions, has a central role in scientific data analysis, machine learning, robotics, cognitive science and artificial intelligence. This Review provides an introduction to this framework, and discusses some of the state-of-the-art advances in the field, namely, probabilistic programming, Bayesian optimization, data compression and automatic model discovery.},
   doi = {10.1038/nature14541}
}




@article{SoltanolkotabiCandes:2012:SubspaceClustering,
   year = {2012},
   author = {Soltanolkotabi, Mahdi and Candes, Emmanuel J.},
   title = {A geometric analysis of subspace clustering with outliers},
   journal = {Annals of Statistics},
   pages = {2195-2238},
   abstract = {This paper considers the problem of clustering a collection of unlabeled data points assumed to lie near a union of lower-dimensional planes. As is common in computer vision or unsupervised learning applications, we do not know in advance how many subspaces there are nor do we have any information about their dimensions. We develop a novel geometric analysis of an algorithm named sparse subspace clustering (SSC) [In IEEE Conference on Computer Vision and Pattern Recognition, 2009. CVPR 2009 (2009) 2790-2797. IEEE], which significantly broadens the range of problems where it is provably effective. For instance, we show that SSC can recover multiple subspaces, each of dimension comparable to the ambient dimension. We also prove that SSC can correctly cluster data points even when the subspaces of interest intersect. Further, we develop an extension of SSC that succeeds when the data set is corrupted with possibly overwhelmingly many outliers. Underlying our analysis are clear geometric insights, which may bear on other sparse recovery problems. A numerical study complements our theoretical analysis and demonstrates the effectiveness of these methods.},
   doi = {10.1214/12-AOS1034}
}


@article{GoodSu:2013:CrowdsourcingBioinfo,
   year = {2013},
   author = {Good, Benjamin M. and Su, Andrew I.},
   title = {Crowdsourcing for bioinformatics},
   journal = {Bioinformatics},
   volume = {29},
   number = {16},
   pages = {1925-1933},
   abstract = {Motivation: Bioinformatics is faced with a variety of problems that require human involvement. Tasks like genome annotation, image analysis, knowledge-base population and protein structure determination all benefit from human input. In some cases, people are needed in vast quantities, whereas in others, we need just a few with rare abilities. Crowdsourcing encompasses an emerging collection of approaches for harnessing such distributed human intelligence. Recently, the bioinformatics community has begun to apply crowdsourcing in a variety of contexts, yet few resources are available that describe how these human-powered systems work and how to use them effectively in scientific domains.Results: Here, we provide a framework for understanding and applying several different types of crowdsourcing. The framework considers two broad classes: systems for solving large-volume ‘microtasks’ and systems for solving high-difficulty ‘megatasks’. Within these classes, we discuss system types, including volunteer labor, games with a purpose, microtask markets and open innovation contests. We illustrate each system type with successful examples in bioinformatics and conclude with a guide for matching problems to crowdsourcing solutions that highlights the positives and negatives of different approaches.Contact: bgood@scripps.edu},
   doi = {10.1093/bioinformatics/btt333},
   url = {http://bioinformatics.oxfordjournals.org/content/29/16/1925.abstract}
}

@article{WangEtAl:2012:AssistiveTaggingHCI,
   year = {2012},
   author = {Wang, Meng and Ni, Bingbing and Hua, Xian-Sheng and Chua, Tat-Seng},
   title = {Assistive tagging: A survey of multimedia tagging with human-computer joint exploration},
   journal = {ACM Computing Surveys},
   volume = {44},
   number = {4},
   pages = {1-24},
   abstract = {Along with the explosive growth of multimedia data, automatic multimedia tagging has attracted great interest of various research communities, such as computer vision, multimedia, and information retrieval. However, despite the great progress achieved in the past two decades, automatic tagging technologies still can hardly achieve satisfactory performance on real-world multimedia data that vary widely in genre, quality, and content. Meanwhile, the power of human intelligence has been fully demonstrated in the Web 2.0 era. If well motivated, Internet users are able to tag a large amount of multimedia data. Therefore, a set of new techniques has been developed by combining humans and computers for more accurate and efficient multimedia tagging, such as batch tagging, active tagging, tag recommendation, and tag refinement. These techniques are able to accomplish multimedia tagging by jointly exploring humans and computers in different ways. This article refers to them collectively as assistive tagging and conducts a comprehensive survey of existing research efforts on this theme. We first introduce the status of automatic tagging and manual tagging and then state why assistive tagging can be a good solution. We categorize existing assistive tagging techniques into three paradigms: (1) tagging with data selection & organization; (2) tag recommendation; and (3) tag processing. We introduce the research efforts on each paradigm and summarize the methodologies. We also provide a discussion on several future trends in this research direction.},
   doi = {10.1145/2333112.2333120}
}

@inproceedings{TodericiEtAl:2010:youtubeTagRecommendation,
   year = {2010},
   author = {Toderici, George and Aradhye, Hrishikesh and Paşca, Marius and Sbaiz, Luciano and Yagnik, Jay},
   title = {Finding meaning on youtube: Tag recommendation and category discovery},
   booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2010) },
   publisher = {IEEE},
   pages = {3447-3454},
   abstract = {We present a system that automatically recommends tags for YouTube videos solely based on their audiovisual content. We also propose a novel framework for unsupervised discovery of video categories that exploits knowledge mined from the World-Wide Web text documents/searches. First, video content to tag association is learned by training classifiers that map audiovisual content-based features from millions of videos on YouTube.com to existing uploader-supplied tags for these videos. When a new video is uploaded, the labels provided by these classifiers are used to automatically suggest tags deemed relevant to the video. Our system has learned a vocabulary of over 20,000 tags. Secondly, we mined large volumes of Web pages and search queries to discover a set of possible text entity categories and a set of associated is-A relationships that map individual text entities to categories. Finally, we apply these is-A relationships mined from web text on the tags learned from audiovisual content of videos to automatically synthesize a reliable set of categories most relevant to videos - along with a mechanism to predict these categories for new uploads. We then present rigorous rating studies that establish that: (a) the average relevance of tags automatically recommended by our system matches the average relevance of the uploader-supplied tags at the same or better coverage and (b) the average precision@K of video categories discovered by our system is 70% with K = 5.},
   doi = {10.1109/CVPR.2010.5539985}
}


@article{Shepard:1962:Proximities,
   year = {1962},
   author = {Shepard, Roger N},
   title = {The analysis of proximities: Multidimensional scaling with an unknown distance function},
   journal = {Psychometrika},
   volume = {27},
   number = {2},
   pages = {125-140}
}

@incollection{GoldstoneEtAl:2010:Comparison,
   year = {2010},
   author = {Goldstone, Robert L and Day, Sam and Son, Ji Y},
   title = {Comparison},
   booktitle = {Towards a Theory of Thinking},
   editor = {Glatzeder, Britt and Goel, Vinod and M{\"u}ller, Albrecht},
   publisher = {Springer},
   address = {Berlin Heidelberg},
   pages = {103-121},
   abstract = {The process of comparison plays a critical role in problem solving, judgment, decision making, categorization, and cognition, broadly construed. In turn, determination of similarities and differences plays a critical role for comparison. In this chapter, we describe important classes of formal models of similarity and comparison: geometric, featural, alignment-based, and transformational. We also consider the question of whether similarity is too flexible to provide a stable ground for cognition, and conversely, whether it is insufficiently flexible to account for the sophistication of cognition. Both similarity assessments and comparison are argued to provide valuable general-purpose cognitive strategies.},
   doi = {10.1007/978-3-642-03129-8_7},
   url = {http://dx.doi.org/10.1007/978-3-642-03129-8_7}
}

@inproceedings{MuellerSeidl:2008:InteractiveSubspaceClustering,
   year = {2008},
   author = {M{\"u}ller, Emmanuel and Assent, Ira and Krieger, Ralph and Jansen, Timm and Seidl, Thomas},
   title = {Morpheus: interactive exploration of subspace clustering},
   booktitle = {Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining KDD 08},
   publisher = {ACM},
   pages = {1089-1092},
   abstract = {Data mining techniques extract interesting patterns out of large data resources. Meaningful visualization and interactive exploration of patterns are crucial for knowledge discovery. Visualization techniques exist for traditional clustering in low dimensional spaces. In high dimensional data, clusters typically only exist in subspace projections. This subspace clustering, however, lacks interactive visualization tools. Challenges arise from typically large result sets in different subspace projections that hinder comparability, visualization and understandability. In this work, we describe Morpheus, a tool that supports the knowledge discovery process through visualization and interactive exploration of subspace clusterings. Users may browse an overview of the entire subspace clustering, analyze subspace cluster characteristics in-depth and zoom into object groupings. Bracketing of different parameter settings enables users to immediately see the effects of parameters and to provide feedback to further improve the subspace clustering. Furthermore, Morpheus may serve as a teaching and exploration tool for the data mining community to visually assess different subspace clustering paradigms.},
   doi = {10.1145/1401890.1402026}
}

@incollection{Hund:2015:SubspaceClustering,
   year = {2015},
   author = {Hund, Michael and Sturm, Werner and Schreck, Tobias and Ullrich, Torsten and Keim, Daniel and Majnaric, Ljiljana and Holzinger, Andreas},
   title = {Analysis of Patient Groups and Immunization Results Based on Subspace Clustering},
   booktitle = {Brain Informatics and Health, Lecture Notes in Artificial Intelligence LNAI 9250},
   editor = {Guo, Yike and Friston, Karl and Aldo, Faisal and Hill, Sean and Peng, Hanchuan},
   publisher = {Springer International Publishing},
   address = {Cham},
   volume = {9250},
   pages = {358-368},
   abstract = {Biomedical experts are increasingly confronted with what is often called Big Data, an important subclass of high-dimensional data. High-dimensional data analysis can be helpful in finding relationships between records and dimensions. However, due to data complexity, experts are decreasingly capable of dealing with increasingly complex data. Mapping higher dimensional data to a smaller number of relevant dimensions is a big challenge due to the curse of dimensionality. Irrelevant, redundant, and conflicting dimensions affect the effectiveness and efficiency of analysis. Furthermore, the possible mappings from high- to low-dimensional spaces are ambiguous. For example, the similarity between patients may change by considering different combinations of relevant dimensions (subspaces). We show the potential of subspace analysis for the interpretation of high-dimensional medical data. Specifically, we analyze relationships between patients, sets of patient attributes, and outcomes of a vaccination treatment by means of a subspace clustering approach. We present an analysis workflow and discuss future directions for high-dimensional (medical) data analysis and visual exploration [machine learning, knowledge discovery, biomedical informatics].},
   doi = {10.1007/978-3-319-23344-4_35}
}




@inproceedings{PuppeEtAl:2006:InteractiveKnowledgeRefinement,
   year = {2006},
   author = {Atzm{\"u}ller, Martin and Baumeister, Joachim and Puppe, Frank},
   title = {Introspective Subgroup Analysis for Interactive Knowledge Refinement},
   booktitle = {FLAIRS Nineteenth International Florida Artificial Intelligence Research Society Conference},
   editor = {Sutcliffe, Geoff and Goebel, Randy},
   publisher = {AAAI Press},
   pages = {402-407},
   abstract = {When knowledge systems are deployed into a real-world application, then the maintenance and the refinement of the knowledge are essential tasks. Many existing automatic knowledge refinement methods only provide limited control and clarification capabilities during the refinement process. Furthermore, often assumptions about the correctness of the knowledge base and the cases are made. However, such assumptions do not necessarily hold for real-world applications. In this paper, we present a novel interactive approach for the refinement of knowledge bases: Subgroup mining is used to discover local patterns that describe factors potentially causing incorrect behavior of the knowledge system. The approach is supplemented by introspective subgroup analysis techniques in order to help the user with the interpretation of the refinement recommendations proposed by the system.}
}

@incollection{Kieseberg:2015:WitnessesDiL,
   year = {2015},
   author = {Kieseberg, Peter and Schantl, Johannes and Fr{\"u}wirt, Peter and Weippl, Edgar and Holzinger, Andreas},
   title = {Witnesses for the Doctor in the Loop},
   booktitle = {Brain Informatics and Health, Lecture Notes in Artificial Intelligence LNAI 9250},
   editor = {Guo, Yike and Friston, Karl and Aldo, Faisal and Hill, Sean and Peng, Hanchuan},
   publisher = {Springer},
   address = {Heidelberg, Berlin},
   pages = {369-378},
   abstract = {The “doctor in the loop” is a new paradigm in information driven medicine, picturing the doctor as authority inside a loop supplying an expert system with information on actual patients, treatment results and possible additional (side-)effects, as well as general information in order to enhance data driven medical science, as well as giving back treatment advice to the doctor himself. While this approach offers several positive aspects related to P4 medicine (personal, predictive, preventive and participatory), it also relies heavily on the authenticity of the data and increases the reliance on the security of databases, as well as on the correctness of machine learning algorithms. In this paper we propose a solution in order to protect the doctor in the loop against responsibility derived from manipulated data, thus enabling this new paradigm to gain acceptance in the medical community.},
   keywords = {P4 medicine, Fingerprinting, Data driven science},
   %doi = {10.1007/978-3-319-23344-4_36}
}



@incollection{Settles:2011:ActiveLearningPractice,
   year = {2011},
   author = {Settles, Burr},
   title = {From theories to queries: Active learning in practice},
   booktitle = {Active Learning and Experimental Design Workshop 2010},
   editor = {Guyon, Isabelle and Cawley, Gavin and Dror, Gideon and Lemaire, Vincent and Statnikov, Alexander},
   publisher = {JMLR Proceedings},
   address = {Sardinia},
   volume = {16},
   pages = {1-18},
   abstract = {This article surveys recent work in active learning aimed at making it more practical for real-world use. In general, active learning systems aim to make machine learning more economical, since they can participate in the acquisition of their own training data. An active learner might iteratively select informative query instances to be labeled by an oracle, for example. Work over the last two decades has shown that such approaches are effective at maintaining accuracy while reducing training set size in many machine learning applications. However, as we begin to deploy active learning in real ongoing learning systems and data annotation projects, we are encountering unexpected problems due in part to practical realities that violate the basic assumptions of earlier foundational work. I review some of these issues, and discuss recent work being done to address the challenges. }
}



@article{Samuel:1959:machineLearningCheckers,
   year = {1959},
   author = {Samuel, Arthur L},
   title = {Some studies in machine learning using the game of checkers},
   journal = {IBM Journal of research and development},
   volume = {3},
   number = {3},
   pages = {210-229},
   abstract = {In the 1950s, Arthur Samuel created one of the first board game-playing programs of any kind. More recently, in 2007 scientists at the University of Alberta developed their "Chinook" program to the point where it is unbeatable. A brute force approach that took hundreds of computers working nearly two decades was used to solve the game,[18] showing that a game of draughts will always end in a draw if neither player makes a mistake.[19][20] The solution is for the draughts variation called go-as-you-please (GAYP) checkers and not for the variation called three-move restriction checkers. As of December 2007, this makes English draughts the most complex game ever solved.}
}


@article{Spinrad:2014:GoogleCar,
   year = {2014},
   author = {Spinrad, Norman},
   title = {Google car takes the test},
   journal = {Nature},
   volume = {514},
   number = {7523},
   pages = {528-528},
   doi = {10.1038/514528a}
   %url = {http://dx.doi.org/10.1038/514528a}
}

@book{Holzinger:2014:SpringerTextbook,
   year = {2014},
   author = {Holzinger, Andreas},
   title = {Biomedical Informatics: Discovering Knowledge in Big Data},
   publisher = {Springer},
   address = {New York},
   abstract = {This book provides a broad overview of the topic Bioinformatics (medical informatics + biological information) with a focus on data, information and knowledge. From data acquisition and storage to visualization, privacy, regulatory, and other practical and theoretical topics, the author touches on several fundamental aspects of the innovative interface between the medical and computational domains that form biomedical informatics. Each chapter starts by providing a useful inventory of definitions and commonly used acronyms for each topic, and throughout the text, the reader finds several real-world examples, methodologies, and ideas that complement the technical and theoretical background. Also at the beginning of each chapter a new section called key problems, has been added, where the author discusses possible traps and unsolvable or major problems. This new edition includes new sections at the end of each chapter, called future outlook and research avenues, providing pointers to future challenges.},
   doi = {10.1007/978-3-319-04528-3}
}

@article{Holzinger:2014:trends,
   year = {2014},
   author = {Holzinger, Andreas},
   title = {Trends in Interactive Knowledge Discovery for Personalized Medicine: Cognitive Science meets Machine Learning},
   journal = {IEEE Intelligent Informatics Bulletin},
   volume = {15},
   number = {1},
   pages = {6-14},
   abstract = {A grand goal of future medicine is in modelling the complexity of patients to tailor medical decisions, health practices and therapies to the individual patient. This trend towards personalized medicine produces unprecedented amounts of data, and even though the fact that human experts are excellent at pattern recognition in dimensions of smaller than three, the problem is that most biomedical data is in dimensions much higher than three, making manual analysis difficult and often impossible. Experts in daily medical routine are decreasingly capable of dealing with the complexity of such data. Moreover, they are not interested the data, they need knowledge and insight in order to support their work. Consequently, a big trend in computer science is to provide efficient, useable and useful computational methods, algorithms and tools to discover knowledge and to interactively gain insight into high-dimensional data. A synergistic combination of methodologies of two areas may be of great help here: Human–Computer Interaction (HCI) and Knowledge Discovery/Data Mining (KDD), with the goal of supporting human intelligence with machine learning. A trend in both disciplines is the acquisition and adaptation of representations that support efficient learning. Mapping higher dimensional data into lower dimensions is a major task in HCI, and a concerted effort of computational methods including recent advances from graphtheory and algebraic topology may contribute to finding solutions. Moreover, much biomedical data is sparse, noisy and timedependent, hence entropy is also amongst promising topics. This paper provides a rough overview of the HCI-KDD approach and focuses on three future trends: graph-based mining, topological data mining and entropy-based data mining.[interactive machine learning]}
   %url = {http://www.comp.hkbu.edu.hk/~cib/2014/Dec/article2/iib_vol15no1_article2.pdf}
}

@incollection{Holzinger:2013:HCI-KDD,
   year = {2013},
   author = {Holzinger, Andreas},
   title = {Human-–Computer Interaction and Knowledge Discovery ({HCI-KDD}): What is the benefit of bringing those two fields to work together?},
   booktitle = {Multidisciplinary Research and Practice for Information Systems, Springer Lecture Notes in Computer Science LNCS 8127},
   editor = {Cuzzocrea, Alfredo and Kittl, Christian and Simos, Dimitris E. and Weippl, Edgar and Xu, Lida},
   publisher = {Springer},
   address = {Heidelberg, Berlin, New York},
   pages = {319-328},
   abstract = {A major challenge in our networked world is the increasing amount of data, which require efficient and user-friendly solutions. A timely example is the biomedical domain: the trend towards personalized medicine has resulted in a sheer mass of the generated (-omics) data. In the life sciences domain, most data models are characterized by complexity, which makes manual analysis very time-consuming and frequently practically impossible. Computational methods may help; however, we must acknowledge that the problem-solving knowledge is located in the human mind and – not in machines. A strategic aim to find solutions for data intensive problems could lay in the combination of two areas, which bring ideal pre-conditions: Human–Computer Interaction (HCI) and Knowledge Discovery (KDD). HCI deals with questions of human perception, cognition, intelligence, decision-making and interactive techniques of visualization, so it centers mainly on supervised methods. KDD deals mainly with questions of machine intelligence and data mining, in particular with the development of scalable algorithms for finding previously unknown relationships in data, thus centers on automatic computational methods. A proverb attributed perhaps incorrectly to Albert Einstein illustrates this perfectly: “Computers are incredibly fast, accurate, but stupid. Humans are incredibly slow, inaccurate, but brilliant. Together they may be powerful beyond imagination”. Consequently, a novel approach is to combine HCI & KDD in order to enhance human intelligence by computational intelligence. },
   keywords = {Human-Computer Interaction (HCI), Knowledge Discovery in Data (KDD), HCI-KDD, E-Science, Interdisciplinary, Intersection science},
    %url = {https://online.tugraz.at/tug_online/voe_main2.getVollText?pDocumentNr=382991&pCurrPk=72064}
}

@article{HolzingerEtAl:2014:KDDBio,
   year = {2014},
   author = {Holzinger, Andreas and Dehmer, Matthias and Jurisica, Igor},
   title = {Knowledge Discovery and interactive Data Mining in Bioinformatics - State-of-the-Art, future challenges and research directions},
   journal = {BMC Bioinformatics},
   volume = {15},
   number = {S6},
   pages = {I1},
   abstract = {The life sciences, biomedicine and health care are increasingly turning into a data intensive science. Particularly in bioinformatics and computational biology we face not only increased volume and a diversity of highly complex, multi-dimensional and often weakly-structured and noisy data, but also the growing need for integrative analysis and modeling. Due to the increasing trend towards personalized and precision medicine (P4 medicine: Predictive, Preventive, Participatory, Personalized), biomedical data today results from various sources in different structural dimensions, ranging from the microscopic world, and in particular from the omics world (e.g., from genomics, proteomics, metabolomics, lipidomics, transcriptomics, epigenetics, microbiomics, fluxomics, phenomics, etc.) to the macroscopic world (e.g., disease spreading data of populations in public health informatics). The challenge is not only to extract meaningful information from this data, but to gain knowledge, to discover previously unknown insight, look for patterns, and to make sense of the data. },
   keywords = {Knowledge Discovery, Interactive Data Mining, Bioinformatics, Biomedical Informatics, Data intensive Science},
   doi = {doi:10.1186/1471-2105-15-S6-I1},
   url = {http://www.biomedcentral.com/1471-2105/15/S6/I1}
}

@inproceedings{YueJoachims:2009:ILOsearch,
   year = {2009},
   author = {Yue, Yisong and Joachims, Thorsten},
   title = {Interactively optimizing information retrieval systems as a dueling bandits problem},
   booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning (ICML)},
   publisher = {ACM},
   pages = {1201-1208},
   abstract = {We present an on-line learning framework tailored towards real-time learning from observed user behavior in search engines and other information retrieval systems. In particular, we only require pairwise comparisons which were shown to be reliably inferred from implicit feedback (Joachims et al., 2007; Radlinski et al., 2008b). We will present an algorithm with theoretical guarantees as well as simulation results.},
   doi = {10.1145/1553374.1553527}
}

@article{YueJoachims:2012:DuelingBandits,
   year = {2012},
   author = {Yue, Yisong and Broder, Josef and Kleinberg, Robert and Joachims, Thorsten},
   title = {The K-armed dueling bandits problem},
   journal = {Journal of Computer and System Sciences},
   volume = {78},
   number = {5},
   pages = {1538-1556},
   abstract = {We study a partial-information online-learning problem where actions are restricted to noisy comparisons between pairs of strategies (also known as bandits). In contrast to conventional approaches that require the absolute reward of the chosen strategy to be quantifiable and observable, our setting assumes only that (noisy) binary feedback about the relative reward of two chosen strategies is available. This type of relative feedback is particularly appropriate in applications where absolute rewards have no natural scale or are difficult to measure (e.g., user-perceived quality of a set of retrieval results, taste of food, product attractiveness), but where pairwise comparisons are easy to make. We propose a novel regret formulation in this setting, as well as present an algorithm that achieves information-theoretically optimal regret bounds (up to a constant factor).},
   keywords = {Online learning
Multi-armed bandits
Preference elicitation},
   doi = {http://dx.doi.org/10.1016/j.jcss.2011.12.028},
   url = {http://www.sciencedirect.com/science/article/pii/S0022000012000281}
}

@incollection{ViappianiBoutilier:2010Bayesian,
title = {Optimal Bayesian Recommendation Sets and Myopically Optimal Choice Query Sets},
author = {Paolo Viappiani and Craig Boutilier},
booktitle = {Advances in Neural Information Processing Systems 23},
editor = {J.D. Lafferty and C.K.I. Williams and J. Shawe-Taylor and R.S. Zemel and A. Culotta},
pages = {2352--2360},
year = {2010},
publisher = {Curran},
url = {http://papers.nips.cc/paper/3943-optimal-bayesian-recommendation-sets-and-myopically-optimal-choice-query-sets.pdf}
}


@inproceedings{FailsOlsen:2003:imlIUI,
   year = {2003},
   author = {Fails, Jerry Alan and Dan R. Olsen, Jr.},
   title = {Interactive machine learning},
   publisher = {ACM},
   pages = {39-45},
   abstract = {Perceptual user interfaces (PUIs) are an important part of ubiquitous computing. Creating such interfaces is difficult because of the image and signal processing knowledge required for creating classifiers. We propose an interactive machine-learning (IML) model that allows users to train, classify/view and correct the classifications. The concept and implementation details of IML are discussed and contrasted with classical machine learning models. Evaluations of two algorithms are also presented. We also briefly describe Image Processing with Crayons (Crayons), which is a tool for creating new camera-based interfaces using a simple painting metaphor. The Crayons tool embodies our notions of interactive machine learning},
   doi = {10.1145/604045.604056},
}

@incollection{AkrourEtAl:2011:PolicyLearning,
   year = {2011},
   author = {Akrour, Riad and Schoenauer, Marc and Sebag, Michele},
   title = {Preference-Based Policy Learning},
   booktitle = {Machine Learning and Knowledge Discovery in Databases, LNAI 6911},
   editor = {Gunopulos, Dimitrios and Hofmann, Thomas and Malerba, Donato and Vazirgiannis, Michalis},
   publisher = {Springer},
   address = {Berlin Heidelberg},
   pages = {12-27},
   abstract = {Many machine learning approaches in robotics, based on reinforcement learning, inverse optimal control or direct policy learning, critically rely on robot simulators. This paper investigates a simulatorfree direct policy learning, called Preference − based Policy Learning (PPL). PPL iterates a four-step process: the robot demonstrates a candidate policy; the expert ranks this policy comparatively to other ones according to her preferences; these preferences are used to learn a policy return estimate; the robot uses the policy return estimate to build new candidate policies, and the process is iterated until the desired behavior is obtained. PPL requires a good representation of the policy search space be available, enabling one to learn accurate policy return estimates and limiting the human ranking effort needed to yield a good policy. Furthermore, this representation cannot use informed features (e.g., how far the robot is from any target) due to the simulator-free setting. As a second contribution, this paper proposes a representation based on the agnostic exploitation of the robotic log. The convergence of PPL is analytically studied and its experimental validation on two problems, involving a single robot in a maze and two interacting robots, is presented.},
   doi = {10.1007/978-3-642-23780-5_11},
   url = {http://dx.doi.org/10.1007/978-3-642-23780-5_11}
}


@article{FuernkranzEtAl:2012:PreferenceBasedRL,
   year = {2012},
   author = {F\"{u}rnkranz, Johannes and H\"{u}llermeier, Eyke and Cheng, Weiwei and Park, Sang-Hyeun},
   title = {Preference-based reinforcement learning: a formal framework and a policy iteration algorithm},
   journal = {Machine Learning},
   volume = {89},
   number = {1-2},
   pages = {123-156},
   abstract = {This paper makes a first step toward the integration of two subfields of machine learning, namely preference learning and reinforcement learning (RL). An important motivation for a preference-based approach to reinforcement learning is the observation that in many real-world domains, numerical feedback signals are not readily available, or are defined arbitrarily in order to satisfy the needs of conventional RL algorithms. Instead, we propose an alternative framework for reinforcement learning, in which qualitative reward signals can be directly used by the learner. The framework may be viewed as a generalization of the conventional RL framework in which only a partial order between policies is required instead of the total order induced by their respective expected long-term reward. Therefore, building on novel methods for preference learning, our general goal is to equip the RL agent with qualitative policy models, such as ranking functions that allow for sorting its available actions from most to least promising, as well as algorithms for learning such models from qualitative feedback. As a proof of concept, we realize a first simple instantiation of this framework that defines preferences based on utilities observed for trajectories. To that end, we build on an existing method for approximate policy iteration based on roll-outs. While this approach is based on the use of classification methods for generalization and policy learning, we make use of a specific type of preference learning method called label ranking. Advantages of preference-based approximate policy iteration are illustrated by means of two case studies.},
   keywords = {Reinforcement learning
Preference learning},
   doi = {10.1007/s10994-012-5313-8},
   url = {http://dx.doi.org/10.1007/s10994-012-5313-8}
}





@incollection{BrochuEtAl2007ActiveLearning,
   year = {2007},
   author = {Brochu, Eric and Freitas, Nando D. and Ghosh, Abhijeet},
   title = {Active preference learning with discrete choice data},
   booktitle = {Advances in neural information processing systems 20 (NIPS 2007)},
   editor = {Platt, J.C. and Koller, D. and Singer, Y. and Roweis, S.T.},
   publisher = {Neural Information Processing Systems Foundation},
   pages = {409-416},
   abstract = {We propose an active learning algorithm that learns a continuous valuation model from discrete preferences. The algorithm automatically decides what items are best presented to an individual in order to find the item that they value highly in as few trials as possible, and exploits quirks of human psychology to minimize time and cognitive burden. To do this, our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive. The problem is particularly difficult because the space of choices is infinite. We demonstrate the effectiveness of the new algorithm compared to related active learning methods. We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials. The tool finds the best parameters while minimizing the number of queries.},
   url = {http://papers.nips.cc/paper/3219-active-preference-learning-with-discrete-choice-data}
}


@inproceedings{Chu:Ghahramani:2005:PreferenceGaussian,
   year = {2005},
   author = {Chu, Wei and Ghahramani, Zoubin},
   title = {Preference learning with Gaussian processes},
   booktitle = {Proceedings of the 22nd international conference on Machine learning},
   publisher = {ACM},
   pages = {137-144},
   abstract = {In this paper, we propose a probabilistic kernel approach to preference learning based on Gaussian processes. A new likelihood function is proposed to capture the preference relations in the Bayesian framework. The generalized formulation is also applicable to tackle many multiclass problems. The overall approach has the advantages of Bayesian methods for model selection and probabilistic prediction. Experimental results compared against the constraint classification approach on several benchmark datasets verify the usefulness of this algorithm.},
   doi = {10.1145/1102351.1102369},
   url = {http://dl.acm.org/citation.cfm?id=1102369}
}


@article{Turing:1950:Mind,
   year = {1950},
   author = {Turing, Alan M},
   title = {Computing machinery and intelligence},
   journal = {Mind},
   volume = {59},
   number = {236},
   pages = {433-460}
}


@book{SuttonBarto:1998:ReinforcementLearning,
   year = {1998},
   author = {Sutton, Richard S and Barto, Andrew G},
   title = {Reinforcement learning: An introduction},
   publisher = {MIT press},
   address = {Cambridge},
   abstract = {This textbook presents a comprehensive introduction to the exciting field of reinforcement learning. Written by two of the pioneers in this field, it provides students, practitioners, and researchers with an intuitive understanding of the central concepts of reinforcement learning as well as a precise presentation of the underlying mathematics. The book also communicates the excitement of recent practical applications of reinforcement learning and the relationship of reinforcement learning to the core questions in artifical intelligence. Reinforcement learning promises to be an extremely important new technology with immense practical impact and important scientific insights into the organization of intelligent systems. The goal of building systems that can adapt to their environments and learn from their experience has attracted researchers from many fields, including computer science, engineering, mathematics, physics, neuroscience, and cognitive science. Out of this research has come a wide variety of learning techniques that have the potential to transform many industrial and scientific fields. Recently, several research communities have begun to converge on a common set of issues surrounding supervised, unsupervised, and reinforcement learning problems. The MIT Press series on Adaptive Computation and Machine Learning seeks to unify the many diverse strands of machine learning research and to foster high quality research and innovative applications. }
}


@article{MinhEtAl:2015:ReinforcementLearningNature,
   year = {2015},
   author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
   title = {Human-level control through deep reinforcement learning},
   journal = {Nature},
   volume = {518},
   number = {7540},
   pages = {529-533},
   abstract = {The theory of reinforcement learning provides a normative account 1 , deeply rooted in psychological 2 and neuroscientific 3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchicalsensory processing systems 4,5 , the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms 3 . While reinforcement learning agents have achieved some successes in a variety of domains 6–8 , their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks9–11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games 12 . We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks },
   doi = {10.1038/nature14236
http://www.nature.com/nature/journal/v518/n7540/abs/nature14236.html#supplementary-information},
   url = {http://dx.doi.org/10.1038/nature14236}
}

@article{Littman:2015:ReinforcementLearningNature,
   year = {2015},
   author = {Littman, Michael L.},
   title = {Reinforcement learning improves behaviour from evaluative feedback},
   journal = {Nature},
   volume = {521},
   number = {7553},
   pages = {445-451},
   abstract = {Reinforcement learning is a branch of machine learning concerned with using experience gained through interacting with the world and evaluative feedback to improve a system's ability to make behavioural decisions. It has been called the artificial intelligence problem in a microcosm because learning algorithms must act autonomously to perform well and achieve their goals. Partly driven by the increasing availability of rich data, recent years have seen exciting advances in the theory and practice of reinforcement learning, including developments in fundamental technical areas such as generalization, planning, exploration and empirical methodology, leading to increasing applicability to real-life problems.},
   doi = {10.1038/nature14540},
   url = {http://dx.doi.org/10.1038/nature14540}
}


@article{JordanMitchell:2015:MLtrendsScience,
   year = {2015},
   author = {Jordan, M. I. and Mitchell, T. M.},
   title = {Machine learning: Trends, perspectives, and prospects},
   journal = {Science},
   volume = {349},
   number = {6245},
   pages = {255-260},
   abstract = {Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today’s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.},
   doi = {10.1126/science.aaa8415},
   url = {http://www.sciencemag.org/content/349/6245/255.abstract}
}


@book{Mitchell:1997:MachineLearningBook,
   year = {1997},
   author = {Mitchell, Tom M},
   title = {Machine learning},
   publisher = {McGraw Hill},
   address = {New York},
   abstract = {The field of machine learning is concerned with the question of how to construct computer programs that automatically improve with experience. In recent  years many successful machine learning applications have been developed, ranging from data-mining programs that learn to detect fraudulent credit card transactions, to information-filtering systems that learn users'  reading preferences, to autonomous vehicles that learn to drive on public highways. At the same time, there have been important advances in the theory and algorithms that form the foundations of this field.}
}

@article{PetzEtAl:2015:Sentiment,
   year = {2015},
   author = {Petz, Gerald and Karpowicz, Michał and Fürschuß, Harald and Auinger, Andreas and Stříteský, Václav and Holzinger, Andreas},
   title = {Computational approaches for mining user’s opinions on the Web 2.0},
   journal = {Information Processing \& Management},
   volume = {51},
   number = {4},
   pages = {510-519},
   abstract = {The emerging research area of opinion mining deals with computational methods in order to find, extract and systematically analyze people’s opinions, attitudes and emotions towards certain topics. While providing interesting market research information, the user generated content existing on the Web 2.0 presents numerous challenges regarding systematic analysis, the differences and unique characteristics of the various social media channels being one of them. This article reports on the determination of such particularities, and deduces their impact on text preprocessing and opinion mining algorithms. The effectiveness of different algorithms is evaluated in order to determine their applicability to the various social media channels. Our research shows that text preprocessing algorithms are mandatory for mining opinions on the Web 2.0 and that part of these algorithms are sensitive to errors and mistakes contained in the user generated content.},
   keywords = {Opinion mining
Noisy text
Text preprocessing
User generated content
Data mining},
   doi = {http://dx.doi.org/10.1016/j.ipm.2014.07.011},
   url = {http://www.sciencedirect.com/science/article/pii/S0306457315000655}
}

@article{KaelblingEtAl:1996:ReinforcementLearning,
   year = {1996},
   author = {Kaelbling, L. P. and Littman, M. L. and Moore, A. W.},
   title = {Reinforcement learning: A survey},
   journal = {Journal of Artificial Intelligence Research},
   volume = {4},
   pages = {237-285},
   abstract = {This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word ''reinforcement.'' The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.},
   keywords = {algorithms},
   url = {<Go to ISI>://WOS:A1996UJ31200001}
}

@article{BusoniuEtAl:2008:MARL,
   year = {2008},
   author = {Busoniu, L. and Babuska, R. and De Schutter, B.},
   title = {A comprehensive survey of multiagent reinforcement learning},
   journal = {IEEE Transactions on Systems Man and Cybernetics Part C-Applications and Reviews},
   volume = {38},
   number = {2},
   pages = {156-172},
   abstract = {Multiagent systems are rapidly finding applications in a variety of domains, including robotics, distributed control, telecommunications, and economics. The complexity of many tasks arising in these domains makes them difficult to solve with preprogrammed agent behaviors. The agents must, instead, discover a solution on their own, using learning. A significant part of the research on multiagent learning concerns reinforcement learning techniques. This paper provides a comprehensive survey of multiagent reinforcement learning (MARL). A central issue in the field is the formal statement of the multiagent learning goal. Different viewpoints on this issue have led to the proposal of many different goals, among which two focal points can be distinguished: stability of the agents' learning dynamics, and adaptation to the changing behavior of the other agents. The MARL algorithms described in the literature aim-either explicitly or implicitly-at one of these two goals or at a combination of both, in a fully cooperative, fully competitive, or more general setting. A representative selection of these algorithms is discussed in detail in this paper, together with the specific issues that arise in each category. Additionally, the benefits and challenges of MARL are described along with some of the problem domains where the MARL techniques have been applied. Finally, an outlook for the field is provided.},
   keywords = {distributed control
game theory
multiagent systems
reinforcement},
   doi = {10.1109/tsmcc.2007.913919},
   url = {<Go to ISI>://WOS:000253471800002}
}
@article{Feldman:2000:Nature,
   year = {2000},
   author = {Feldman, J.},
   title = {Minimization of Boolean complexity in human concept learning},
   journal = {Nature},
   volume = {407},
   number = {6804},
   pages = {630-633},
   abstract = {One of the unsolved problems in the field of human concept learning concerns the factors that determine the subjective difficulty of concepts: why are some concepts psychologically simple and easy to learn, while others seem difficult, complex or incoherent? This question was much studied in the 1960s(1) but was never answered, and more recent characterizations of concepts as prototypes rather than logical rules(2,3) leave it unsolved(4-6). Here I investigate this question in the domain of Boolean concepts (categories defined by logical rules). A series of experiments measured the subjective difficulty of a wide range of logical varieties of concepts (41 mathematically distinct types in six families-a for wider range than has been tested previously). The data reveal a surprisingly simple empirical 'law': the subjective difficulty of a concept is directly proportional to its Boolean complexity (the length of the shortest logically equivalent propositional formula)-that is, to its logical incompressibility.},
   doi = {10.1038/35036586}
}

@article{MedinEtAL:1987:inductiveLearning,
   year = {1987},
   author = {Medin, D. L. and Wattenmaker, W. D. and Michalski, R. S.},
   title = {Constraints and Preferences in inductive Learning - an experimental study of Human and Machine Performance},
   journal = {Cognitive Science},
   volume = {11},
   number = {3},
   pages = {299-339},
   abstract = {The paper examines constraints and preferences employed by people in learning decision rules from preclassified examples. Results from four experiments with human subjects were analyzed and compared with artificial intelligence (AI) inductive learning programs. The results showed the people's rule inductions tended to emphasize category validity (probability of some property, given a category) more than cue validity (probability that an entity is a member of a category given that it has some property) to a greater extent than did the AI programs. Although the relative proportions of different rule types (e.g., conjunctive vs. disjunctive) changed across experiments, a single process model provided a good account of the data from each study. These observations are used to argue for describing constraints in terms of processes embodied in models rather than in terms of products or outputs. Thus AI induction programs become candidate psychological process models and results from inductive learning experiments can suggest new algorithms. More generally, the results show that human inductive generalizations tend toward greater specificity than would be expected if conceptual simplicity were the key constraint on inductions. This bias toward specificity may be due to the fact that this criterion both maximizes inferences that may be drawn from category membership and protects rule induction systems from developing over-generalizations.},
   url = {<Go to ISI>://WOS:A1987K702900003}
}

@article{CohnGhahramaniJordan:1996:ActiveLearning,
   year = {1996},
   author = {Cohn, D. A. and Ghahramani, Z. and Jordan, M. I.},
   title = {Active learning with statistical models},
   journal = {Journal of Artificial Intelligence Research},
   volume = {4},
   pages = {129-145},
   abstract = {For many types of machine learning algorithms, one can compute the statistically ''optimal'' way to select training data. In this paper, we review how optimal data selection techniques have been used with feedforward neural networks. We then show how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression. While the techniques for neural networks are computationally expensive and approximate, the techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate. Empirically, we observe that the optimality criterion sharply decreases the number of training examples the learner needs in order to achieve good performance.},
   keywords = {regression},
   doi = {doi:10.1613/jair.295}
}

@incollection{KnoxEtAl:2012:RobotHumanFeedback,
   year = {2013},
   author = {Knox, W. Bradley and Stone, Peter and Breazeal, Cynthia},
   title = {Training a Robot via Human Feedback: A Case Study},
   booktitle = {Social Robotics. Lecture Notes in Artificial Intelligence LNAI 8239},
   editor = {Herrmann, Guido and Pearson, MartinJ and Lenz, Alexander and Bremner, Paul and Spiers, Adam and Leonards, Ute},
   publisher = {Springer},
   address = {Heidelberg, Berlin},
   pages = {460-470},
   abstract = {We present a case study of applying a framework for learning from numeric human feedback—tamer—to a physically embodied robot. In doing so, we also provide the first demonstration of the ability to train multiple behaviors by such feedback without algorithmic modifications and of a robot learning from free-form human-generated feedback without any further guidance or evaluative feedback. We describe transparency challenges specific to a physically embodied robot learning from human feedback and adjustments that address these challenges.},
   doi = {10.1007/978-3-319-02675-6_46},
   url = {http://dx.doi.org/10.1007/978-3-319-02675-6_46}
}

@inproceedings{WeinbergerPara:2010:MultiTaskMetricLearning,
   year = {2010},
   author = {Parameswaran, Shibin and Weinberger, Kilian Q},
   title = {Large margin multi-task metric learning},
   booktitle = {Advances in neural information processing systems 23 (NIPS 2010)},
   editor = {Lafferty, John and Williams, Christopher and Shawe-Taylor, John and Zemel, Richard and Culotta, Aron},
   pages = {1867-1875},
   abstract = {Multi-task learning (MTL) improves the prediction performance on multiple, different but related, learning problems through shared parameters or representations. One of the most prominent multi-task learning algorithms is an extension to svms by Evgeniou et al. Although very elegant, multi-task svm is inherently restricted by the fact that support vector machines require each class to be addressed explicitly with its own weight vector which, in a multi-task setting, requires the different learning tasks to share the same set of classes. This paper proposes an alternative formulation for multi-task learning by extending the recently published large margin nearest neighbor (lmnn) algorithm to the MTL paradigm. Instead of relying on separating hyperplanes, its decision function is based on the nearest neighbor rule which inherently extends to many classes and becomes a natural fit for multitask learning. We evaluate the resulting multi-task lmnn on real-world insurance data and speech classification problems and show that it consistently outperforms single-task kNN under several metrics and state-of-the-art MTL classifiers},
   url = {http://papers.nips.cc/paper/3935-large-margin-multi-task-metric-learning}
}

@inproceedings{WilsonEtAl:2012:PreferenceLearningBayes,
   year = {2012},
   author = {Wilson, Aaron and Fern, Alan and Tadepalli, Prasad},
   title = {A {B}ayesian approach for policy learning from trajectory preference queries},
   booktitle = {Advances in neural information processing systems 25 (NIPS 2012)},
   editor = {Pereira, Fernando and Burges, Christopher and Bottou, Leon and Weinberger, Kilian},
   pages = {1133-1141},
   abstract = {We consider the problem of learning control policies via trajectory preference queries to an expert. In particular, the learning agent can present an expert with short runs of a pair of policies originating from the same state and the expert then indicates the preferred trajectory. The agent's goal is to elicit a latent target policy from the expert with as few queries as possible. To tackle this problem we propose a novel Bayesian model of the querying process and introduce two methods that exploit this model to actively select expert queries. Experimental results on four benchmark problems indicate that our model can effectively learn policies from trajectory preference queries and that active query selection can be substantially more efficient than random selection.},
   url = {http://papers.nips.cc/paper/4805-a-bayesian-approach-for-policy-learning-from-trajectory-preference-queries}
}

@inproceedings{JainJoachimsEtAl:2013:LearningTrajectoryPreferences,
   year = {2013},
   author = {Jain, Ashesh and Wojcik, Brian and Joachims, Thorsten and Saxena, Ashutosh},
   title = {Learning trajectory preferences for manipulators via iterative improvement},
   booktitle = {Advances in Neural Information Processing Systems},
   pages = {575-583},
   abstract = {We consider the problem of learning good trajectories for manipulation tasks. This is challenging because the criterion defining a good trajectory varies with users, tasks and environments. In this paper, we propose a co-active online learning framework for teaching robots the preferences of its users for object manipulation tasks. The key novelty of our approach lies in the type of feedback expected from the user: the human user does not need to demonstrate optimal trajectories as training data, but merely needs to iteratively provide trajectories that slightly improve over the trajectory currently proposed by the system. We argue that this co-active preference feedback can be more easily elicited from the user than demonstrations of optimal trajectories, which are often challenging and non-intuitive to provide on high degrees of freedom manipulators. Nevertheless, theoretical regret bounds of our algorithm match the asymptotic rates of optimal trajectory algorithms. We also formulate a score function to capture the contextual information and demonstrate the generalizability of our algorithm on a variety of household tasks, for whom, the preferences were not only influenced by the object being manipulated but also by the surrounding environment.},
   url = {http://papers.nips.cc/paper/5179-learning-trajectory-preferences-for-manipulators-via-iterative-improvement}
}

@book{Settles:2012:ActiveLearningBook,
   year = {2012},
   author = {Settles, Burr},
   title = {Active Learning},
   publisher = {Morgan and Claypool},
   address = {San Rafael (CA)},
   abstract = {The key idea behind active learning is that a machinelearning algorithm can perform better with less training if it is allowed tochoosethe data from which it learns. An active learner may pose “queries,” usually in the form of unlabeled data instances to be labeled by an “oracle” (e.g., a human annotator) that already understands the nature of the problem. This sort of approach is well-motivated in many modern machine learning and data mining applications, where unlabeled data may be abundant or easy to come by, but training labels are difficult, time-consuming, or expensive to obtain. This book is a general introduction to active learning. It outlines several scenarios in which queries might be formulated, and details many query selection algorithms which have been organized into four broad categories, or “query selection frameworks.” We also touch on some of the theoretical foundations of active learning, and conclude with an overview of the strengths and weaknesses of these approaches in practice, including a summary of ongoing work to address these open challenges and opportunities.},
   keywords = {active learning, expected error reduction, hierarchical sampling, optimal experimental design, query by committee, query by disagreement, query learning, uncertainty sampling, variance reduction},
   doi = {10.2200/S00429ED1V01Y201207AIM018}
}

@incollection{YimamEtAl:2015:InteractiveAnnotation,
   year = {2015},
   author = {Yimam, Seid Muhie and Biemann, Chris and Majnaric, Ljiljana and Sabanovic, Sefket and Holzinger, Andreas},
   title = {Interactive and Iterative Annotation for Biomedical Entity Recognition},
   booktitle = {Brain Informatics and Health, Lecture Notes in Artificial Intelligence LNAI 9250},
   editor = {Guo, Yike and Friston, Karl and Aldo, Faisal and Hill, Sean and Peng, Hanchuan},
   publisher = {Springer},
   address = {Cham},
   pages = {347-357},
   abstract = {In this paper, we demonstrate the impact of interactive machine learning for the development of a biomedical entity recognition dataset using a human-into-the-loop approach: during annotation, a machine learning model is built on previous annotations and used to propose labels for subsequent annotation. To demonstrate that such interactive and iterative annotation speeds up the development of quality dataset annotation, we conduct two experiments. In the first experiment, we carry out an iterative annotation experimental simulation and show that only a handful of medical abstracts need to be annotated to produce suggestions that increase annotation speed. In the second experiment, clinical doctors have conducted a case study in annotating medical terms documents relevant for their research. The experiments validate our method qualitatively and quantitatively, and give rise to a more personalized, responsive information extraction technology [interactive machine learning, Human-in-the-loop].},
   keywords = {Interactive annotation, Machine learning, Knowledge discovery, Data mining, Human in the loop, Biomedical entity recognition},
   doi = {10.1007/978-3-319-23344-4_34}
}

@article{WarmuthEtAl:2003:ActiveLearningDrugDiscovery,
   year = {2003},
   author = {Warmuth, Manfred K and Liao, Jun and Raetsch, Gunnar and Mathieson, Michael and Putta, Santosh and Lemmen, Christian},
   title = {Active learning with support vector machines in the drug discovery process},
   journal = {Journal of Chemical Information and Computer Sciences},
   volume = {43},
   number = {2},
   pages = {667-673},
   abstract = {We investigate the following data mining problem from computer-aided drug design: From a large collection of compounds, find those that bind to a target molecule in as few iterations of biochemical testing as possible. In each iteration a comparatively small batch of compounds is screened for binding activity toward this target. We employed the so-called “active learning paradigm” from Machine Learning for selecting the successive batches. Our main selection strategy is based on themaximum margin hyperplanesgenerated by
“Support Vector Machines”. This hyperplane separates the current set of active from the inactive compounds and has the largest possible distance from any labeled compound. We perform a thorough comparative study of various other selection strategies on data sets provided by DuPont Pharmaceuticals and show that the strategies based on the maximum margin hyperplane clearly outperform the simpler ones.},
   doi = {10.1021/ci025620t}
}

@article{PanYang:2010:SurveyTransferLearning,
   year = {2010},
   author = {Pan, Sinno J. and Yang, Qiang A.},
   title = {A Survey on Transfer Learning},
   journal = {IEEE Transactions on Knowledge and Data Engineering},
   volume = {22},
   number = {10},
   pages = {1345-1359},
   abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
   keywords = {Transfer Learning},
   doi = {10.1109/tkde.2009.191}
}



